{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import src.data.data as data\n",
    "import src.models.lwp as lwp\n",
    "import src.distances.euclidean as euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aujasvit/Desktop/CS771-Mini-Project-2/src/data/data.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeds  = torch.load('embeds/resnet_embeds.pt', map_location = device)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_train, y_train, x_test, y_test = data.resnet_embeddings()\n",
    "x_train = [torch.squeeze(i) for i in x_train]\n",
    "x_test = [torch.squeeze(i) for i in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1:  0.2424\n"
     ]
    }
   ],
   "source": [
    "#initial training\n",
    "x, y = x_train[0], y_train[0]\n",
    "\n",
    "distance = euclidean.EuclideanDistance(device)\n",
    "\n",
    "model = lwp.LearningWithPrototype(\n",
    "    num_classes=10,\n",
    "    device=device,\n",
    "    distance_type=distance,\n",
    "    features=x,\n",
    "    labels=y\n",
    ")\n",
    "print(\"Dataset 1: \", model.eval(x_train[0], y_train[0]))\n",
    "# for i in range(1,20):\n",
    "#     x = x_train[i]\n",
    "#     y = model.predict(x)\n",
    "#     model.update(x, y)\n",
    "#     # print(model.features.shape, model.labels.shape)\n",
    "#     print(f\"Dataset {i + 1}:\", model.eval(x_test[i], y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.2863e+01, 8.8628e+01, 4.5568e+00, 7.2382e+01, 0.0000e+00, 1.1389e+02,\n",
      "        1.7911e+01, 1.1975e+00, 2.3182e+02, 9.8573e+01, 1.9475e+01, 1.1801e+01,\n",
      "        1.6757e+01, 7.5280e+00, 4.3878e+00, 9.5451e-03, 1.1389e+02, 0.0000e+00,\n",
      "        2.0316e+01, 9.3963e+01, 2.0243e-01, 1.1762e+01, 4.6365e-01, 9.4256e+00,\n",
      "        0.0000e+00, 0.0000e+00, 3.2611e+00, 0.0000e+00, 1.9645e+01, 4.5384e+01,\n",
      "        1.0019e+02, 0.0000e+00, 2.5832e+00, 0.0000e+00, 2.1717e+01, 3.9509e+00,\n",
      "        0.0000e+00, 2.2600e+01, 8.7610e+01, 2.4647e+00, 0.0000e+00, 3.8397e+00,\n",
      "        0.0000e+00, 4.0429e+01, 0.0000e+00, 0.0000e+00, 7.4056e+01, 1.0705e+02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2994e+02, 1.3235e+01, 5.6301e+00,\n",
      "        3.5141e+01, 8.9058e-01, 5.6503e+00, 6.3217e+01, 0.0000e+00, 0.0000e+00,\n",
      "        2.8499e+01, 2.6125e+01, 4.5734e+01, 3.0411e+01, 3.8416e+01, 2.9263e+01,\n",
      "        1.6771e+02, 1.0961e+02, 1.4535e+02, 0.0000e+00, 0.0000e+00, 2.2871e+00,\n",
      "        0.0000e+00, 3.5385e+01, 0.0000e+00, 0.0000e+00, 2.1479e+02, 1.6642e+00,\n",
      "        0.0000e+00, 2.0596e+02, 0.0000e+00, 1.9592e+01, 0.0000e+00, 5.1036e+00,\n",
      "        2.3189e+00, 8.8665e-01, 1.9845e-02, 0.0000e+00, 1.7140e+00, 2.2614e+01,\n",
      "        4.3052e-01, 1.2635e+02, 0.0000e+00, 0.0000e+00, 5.1523e-01, 1.5100e+00,\n",
      "        1.0556e+02, 9.5436e-01, 0.0000e+00, 6.7355e+00, 4.6196e+01, 0.0000e+00,\n",
      "        5.7524e+00, 1.2180e+02, 5.3931e+01, 5.6572e+02, 4.0994e+00, 1.1766e+00,\n",
      "        2.7284e+02, 0.0000e+00, 2.6246e+00, 4.2680e+01, 8.8621e+01, 4.5665e+01,\n",
      "        0.0000e+00, 9.9742e+01, 3.8351e+01, 9.1324e+01, 0.0000e+00, 8.9724e+00,\n",
      "        1.3503e+01, 0.0000e+00, 0.0000e+00, 2.3764e+01, 2.9761e+01, 7.5908e-01,\n",
      "        4.4807e+01, 1.6042e+01, 3.3566e+01, 6.7256e+01, 4.0925e+01, 1.4371e+00,\n",
      "        4.4679e+01, 0.0000e+00, 1.2496e+02, 4.0252e+01, 6.7989e+01, 6.2988e+01,\n",
      "        8.3297e+01, 0.0000e+00, 0.0000e+00, 1.2530e+02, 0.0000e+00, 5.8800e+00,\n",
      "        5.2267e+01, 5.3130e+01, 0.0000e+00, 9.1761e+01, 7.6087e+01, 0.0000e+00,\n",
      "        1.2328e+02, 1.1540e+00, 2.7994e+02, 0.0000e+00, 0.0000e+00, 1.0978e+01,\n",
      "        0.0000e+00, 2.7191e+01, 0.0000e+00, 2.5097e+01, 2.6793e+01, 2.5936e+00,\n",
      "        0.0000e+00, 2.2274e+02, 4.7414e+01, 4.6774e+01, 6.6325e+00, 9.6608e+01,\n",
      "        1.1408e+00, 0.0000e+00, 6.5096e+01, 5.0763e+01, 1.3156e+02, 1.3441e+02,\n",
      "        3.3212e+01, 1.5842e+02, 3.6549e-02, 2.5810e+01, 0.0000e+00, 2.7493e+01,\n",
      "        9.0401e+01, 0.0000e+00, 0.0000e+00, 2.3328e+02, 6.5086e+01, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 2.1182e+01, 3.9438e+01, 0.0000e+00, 2.0619e+02,\n",
      "        4.0363e+01, 6.8703e+01, 1.3883e+02, 2.2790e+00, 1.0606e+01, 3.6078e+01,\n",
      "        3.5675e+01, 2.5797e+01, 4.8710e+01, 4.6129e+00, 9.1315e+01, 0.0000e+00,\n",
      "        3.7018e-02, 1.2472e+01, 5.9912e+00, 6.8980e+00, 4.1776e+01, 1.7601e+02,\n",
      "        1.8217e+01, 3.9097e+00, 2.3913e-01, 8.5553e+00, 4.3128e+01, 9.3961e+01,\n",
      "        0.0000e+00, 2.0276e+01, 0.0000e+00, 3.0664e+01, 3.5888e+01, 1.0728e+00,\n",
      "        1.0617e+01, 1.7383e-01, 1.3453e+02, 0.0000e+00, 1.7934e+02, 2.4828e+00,\n",
      "        7.9872e+01, 2.5214e+00, 0.0000e+00, 6.7792e+00, 9.5513e+01, 2.5874e+02,\n",
      "        1.2782e+02, 2.1070e+02, 1.0212e+02, 2.1220e+00, 1.4511e+01, 6.1611e+01,\n",
      "        7.8824e+00, 2.9860e+01, 0.0000e+00, 2.3883e+01, 1.1914e+02, 0.0000e+00,\n",
      "        3.8176e+01, 5.0561e+00, 0.0000e+00, 0.0000e+00, 3.4491e+00, 2.1219e+02,\n",
      "        6.7062e+01, 4.8724e+00, 1.0833e+02, 0.0000e+00, 0.0000e+00, 1.1803e+02,\n",
      "        9.3429e+00, 0.0000e+00, 1.5256e+01, 0.0000e+00, 0.0000e+00, 1.8497e+00,\n",
      "        1.4973e+01, 0.0000e+00, 7.7631e+00, 0.0000e+00, 5.2640e+02, 1.1944e+02,\n",
      "        8.3196e-01, 1.6047e-01, 1.2615e+01, 1.6750e+01, 1.7155e+02, 1.2942e+01,\n",
      "        3.2524e+01, 1.5448e-02, 1.7407e+02, 7.5852e+01, 1.3053e+01, 0.0000e+00,\n",
      "        2.9179e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8454e+00, 5.2134e-01,\n",
      "        5.6909e-01, 1.5995e+01, 2.2037e+01, 1.9007e+00, 0.0000e+00, 3.8815e+01,\n",
      "        1.1714e+02, 1.8471e+02, 2.1413e+01, 0.0000e+00, 5.9021e+00, 2.8071e-01,\n",
      "        1.6631e+02, 9.7911e+01, 1.4472e+02, 0.0000e+00, 4.1988e+01, 0.0000e+00,\n",
      "        1.8901e-01, 5.2692e+00, 3.5015e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 3.4620e+01, 2.8867e+00, 2.3594e+01, 1.7400e+02,\n",
      "        1.2193e+00, 0.0000e+00, 1.8724e+02, 4.1851e+00, 1.6970e+02, 1.5723e+01,\n",
      "        6.6721e+00, 5.6919e+01, 1.6852e+01, 8.1993e+01, 5.4515e+01, 4.8096e+00,\n",
      "        8.8156e+00, 7.7693e+01, 1.1066e+02, 1.0216e+01, 3.2811e+00, 3.2826e+01,\n",
      "        4.1754e+01, 5.9566e+01, 4.1676e-01, 8.6428e+01, 0.0000e+00, 4.1879e+00,\n",
      "        5.2842e-01, 1.1171e+00, 1.6597e+01, 1.8851e+01, 0.0000e+00, 0.0000e+00,\n",
      "        3.2971e+01, 1.9781e+01, 1.6359e+01, 2.1613e-01, 2.2260e-01, 5.2078e+01,\n",
      "        0.0000e+00, 3.5876e-01, 6.0843e+01, 2.3853e+00, 8.6405e+00, 2.7296e+02,\n",
      "        1.2962e+01, 2.1191e+02, 3.7957e+01, 8.5975e-02, 6.9578e+01, 4.9321e+01,\n",
      "        6.3653e+01, 1.2450e-01, 1.8660e+01, 3.6773e+01, 0.0000e+00, 2.2969e+01,\n",
      "        2.9323e+00, 0.0000e+00, 2.7194e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.3183e+01, 3.7393e+00, 0.0000e+00, 3.0027e+02, 6.2692e+01, 3.1067e+00,\n",
      "        0.0000e+00, 4.6210e+01, 1.3702e+01, 3.2017e+01, 0.0000e+00, 6.2717e+01,\n",
      "        9.4686e+01, 3.7873e+00, 1.4760e+01, 0.0000e+00, 2.2972e-01, 5.2329e+01,\n",
      "        1.3389e+02, 0.0000e+00, 5.1181e+01, 1.7890e+00, 7.3267e-01, 7.1014e+01,\n",
      "        8.3497e+01, 1.9665e+01, 3.2777e+02, 3.0461e+01, 1.7202e+01, 2.7614e+00,\n",
      "        8.7840e+00, 8.8609e+01, 1.5557e+00, 0.0000e+00, 1.2946e+02, 3.5653e+01,\n",
      "        6.0818e-01, 2.7242e+01, 1.8531e+01, 3.6568e-01, 1.0225e+02, 5.1286e+01,\n",
      "        0.0000e+00, 0.0000e+00, 1.4072e+01, 5.0250e+01, 4.7358e+01, 0.0000e+00,\n",
      "        9.5705e+01, 0.0000e+00, 0.0000e+00, 1.0855e+02, 3.2433e+00, 7.5353e-01,\n",
      "        0.0000e+00, 0.0000e+00, 7.5518e+00, 5.6282e+01, 3.3858e+01, 0.0000e+00,\n",
      "        4.7095e+01, 0.0000e+00, 1.4869e+01, 3.5121e+01, 4.1378e+01, 1.3758e+02,\n",
      "        2.6855e+01, 2.7548e+02, 0.0000e+00, 1.2395e+00, 2.6529e+01, 9.0298e+00,\n",
      "        2.4248e+01, 8.2524e+01, 6.5284e+00, 6.4991e+00, 0.0000e+00, 9.6881e+01,\n",
      "        3.4342e+01, 4.8890e+01, 5.0777e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        8.4033e+00, 5.0509e+01, 0.0000e+00, 7.1236e+01, 3.2424e+01, 0.0000e+00,\n",
      "        0.0000e+00, 1.2832e+01, 1.1703e+01, 4.9092e+00, 3.0455e+01, 0.0000e+00,\n",
      "        0.0000e+00, 8.0492e+00, 8.9219e+00, 9.8237e+01, 0.0000e+00, 2.5156e+02,\n",
      "        2.7082e+01, 1.8029e+01, 0.0000e+00, 0.0000e+00, 1.6632e+01, 2.2721e+01,\n",
      "        1.0412e+02, 0.0000e+00, 0.0000e+00, 7.2414e+00, 0.0000e+00, 3.8361e+01,\n",
      "        1.1219e+01, 2.1870e+01, 4.4212e-01, 3.8055e+00, 2.0808e+02, 1.3282e+01,\n",
      "        0.0000e+00, 5.6775e-01, 0.0000e+00, 1.8794e+00, 5.5820e+01, 3.1597e-01,\n",
      "        2.1924e+01, 5.7510e+01, 3.4537e+01, 7.9080e+00, 1.0968e+02, 0.0000e+00,\n",
      "        1.1649e+01, 6.2805e+01])\n"
     ]
    }
   ],
   "source": [
    "print(model.features[model.labels == 1][:30][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import src.data.data as data\n",
    "import src.models.lwp as lwp\n",
    "import src.distances.euclidean as euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1,0], [-1, 0]], dtype = torch.float32)\n",
    "y = torch.tensor([0, 1])\n",
    "model = lwp.LearningWithPrototype(\n",
    "    num_classes=2,\n",
    "    device=device,\n",
    "    distance_type=euclidean.EuclideanDistance(device),\n",
    "    features=x,\n",
    "    labels=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval(torch.tensor([[2,0], [-2, 0]], dtype = torch.float32), torch.tensor([0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.update(torch.tensor([[2,0], [-2,0]]), model.predict(torch.tensor([[2,0], [-2,0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1.5000, 0.0000]), tensor([-1.5000,  0.0000])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_prototypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial training\n",
    "x, y = x_train[0], y_train[0]\n",
    "\n",
    "distance = euclidean.EuclideanDistance(device)\n",
    "\n",
    "model = lwp.LearningWithPrototype(\n",
    "    num_classes=10,\n",
    "    device=device,\n",
    "    distance_type=distance,\n",
    "    features=x,\n",
    "    labels=y\n",
    ")\n",
    "print(\"Dataset 1: \", model.eval(x_test[0], y_test[0]))\n",
    "for i in range(1,20):\n",
    "    x = x_train[i]\n",
    "    y = model.predict(x)\n",
    "    model.update(x, y)\n",
    "    print(model.features.shape, model.labels.shape)\n",
    "    # print(f\"Dataset {i + 1}:\", model.eval(x_test[0], y_test[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
