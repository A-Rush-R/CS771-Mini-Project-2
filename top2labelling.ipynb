{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision import models, transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('dataset', 'part_one_dataset', 'train_data')\n",
    "eval_dir = os.path.join('dataset', 'part_one_dataset', 'eval_data')\n",
    "train_path = os.path.join(train_dir, '1_train_data.tar.pth')\n",
    "eval_path = os.path.join(eval_dir, '1_eval_data.tar.pth')\n",
    "\n",
    "t = torch.load(train_path, weights_only = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic LWP Model using Distance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances, manhattan_distances\n",
    "\n",
    "class LWP:\n",
    "    \"\"\"Learning Vector Prototypes with configurable distance function\"\"\"\n",
    "    \n",
    "    DISTANCE_FUNCTIONS = {\n",
    "        'euclidean': lambda x, y: np.linalg.norm(x - y),\n",
    "        'cosine': lambda x, y: cosine_distances(x.reshape(1, -1), y.reshape(1, -1))[0][0],\n",
    "        'manhattan': lambda x, y: manhattan_distances(x.reshape(1, -1), y.reshape(1, -1))[0][0],\n",
    "        'minkowski': lambda x, y, p=2: np.power(np.sum(np.power(np.abs(x - y), p)), 1/p)\n",
    "    }\n",
    "    \n",
    "    def __init__(self, distance_metric='euclidean', **distance_params):\n",
    "        \"\"\"\n",
    "            distance_params (dict): Additional parameters for the distance function\n",
    "        \"\"\"\n",
    "        self.prototypes = {}\n",
    "        self.class_counts = {i: 0 for i in range(10)}\n",
    "        \n",
    "        if callable(distance_metric):\n",
    "            self.distance_fn = distance_metric\n",
    "        elif distance_metric in self.DISTANCE_FUNCTIONS:\n",
    "            if distance_metric == 'minkowski':\n",
    "                p = distance_params.get('p', 2)\n",
    "                self.distance_fn = lambda x, y: self.DISTANCE_FUNCTIONS[distance_metric](x, y, p)\n",
    "            else:\n",
    "                self.distance_fn = self.DISTANCE_FUNCTIONS[distance_metric]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown distance metric: {distance_metric}. \" \n",
    "                           f\"Available metrics: {list(self.DISTANCE_FUNCTIONS.keys())}\")\n",
    "\n",
    "    def fit(self, features, labels):\n",
    "        unique_labels = np.unique(labels)\n",
    "        for label in unique_labels:\n",
    "            samples = features[labels == label]\n",
    "            num_samples = len(samples)\n",
    "            \n",
    "            if label not in self.prototypes:  # Original condition was: if label not in self.prototypes\n",
    "                self.prototypes[label] = samples.mean(axis=0)\n",
    "                self.class_counts[label] = len(samples)\n",
    "            else:\n",
    "                self.class_counts[label] += len(samples)\n",
    "                self.prototypes[label] = (\n",
    "                    (self.class_counts[label] - num_samples) / self.class_counts[label] * self.prototypes[label] +\n",
    "                    num_samples / self.class_counts[label] * samples.mean(axis=0)\n",
    "                )\n",
    "    \n",
    "            \n",
    "    \n",
    "\n",
    "    def predict(self, features):\n",
    "        preds = []\n",
    "        for feature in features:\n",
    "            distances = {\n",
    "                label: self.distance_fn(feature, proto)\n",
    "                for label, proto in self.prototypes.items()\n",
    "            }\n",
    "            preds.append(min(distances, key=distances.get))\n",
    "        return np.array(preds)\n",
    "    \n",
    "    def predict_proba(self, features):\n",
    "        \"\"\"\n",
    "        Predict probabilities (normalized distances to prototypes).\n",
    "        Args:\n",
    "            features (np.array): Embeddings of the data points.\n",
    "        Returns:\n",
    "            np.array: Probabilities for each class.\n",
    "        \"\"\"\n",
    "        prob_list = []\n",
    "        for feature in features:\n",
    "            # Calculate distances to all prototypes\n",
    "            \n",
    "            print('$$$$$$$$$$$$$$DEBUG###############')\n",
    "            \n",
    "            for label, proto in enumerate(self.prototypes.values()) :\n",
    "                print('shape of proto is' , proto.shape)\n",
    "            distances = {\n",
    "                label: self.distance_fn(feature, proto) for label, proto in enumerate(self.prototypes.values())\n",
    "            }\n",
    "            \n",
    "            print('$$$$$$$$$$$$$$DEBUG###############')\n",
    "            # Convert distances to probabilities\n",
    "            exp_neg_distances = np.exp(-np.array(list(distances.values())))  # Exponential of negative distances\n",
    "            probabilities = exp_neg_distances / exp_neg_distances.sum()  # Normalize to sum to 1\n",
    "            \n",
    "            prob_list.append(probabilities)\n",
    "        \n",
    "        return np.vstack(prob_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute cosine similarity and select top samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_samples(embeddings, centroids, top_percentage=0.5):\n",
    "    \"\"\"\n",
    "    Select top-k% samples with highest cosine similarity to centroids\n",
    "    and include top-2 pseudo-labels.\n",
    "    Args:\n",
    "        embeddings (np.array): The data embeddings.\n",
    "        centroids (np.array): Prototypes or centroids for each class.\n",
    "        top_percentage (float): Percentage of top samples to select (0 < top_percentage <= 1).\n",
    "    Returns:\n",
    "        tuple: Top-k% embeddings, top-1 pseudo-labels, and top-2 pseudo-labels.\n",
    "    \"\"\"\n",
    "    if not (0 < top_percentage <= 1):\n",
    "        raise ValueError(\"top_percentage must be between 0 and 1.\")\n",
    "\n",
    "    # Compute similarity scores\n",
    "    similarities = cosine_similarity(embeddings, centroids)\n",
    "\n",
    "    # Compute the number of samples to select (50% of total embeddings)\n",
    "    total_samples = embeddings.shape[0]\n",
    "    top_k = int(total_samples * top_percentage)\n",
    "    print(f\"Selecting top {top_k} samples out of {total_samples} (percentage: {top_percentage * 100}%)...\")\n",
    "\n",
    "    # Find top-k samples with the highest cosine similarity to centroids\n",
    "    max_similarities = np.max(similarities, axis=1)\n",
    "    sorted_indices = np.argsort(max_similarities)[::-1]  # Sort by similarity in descending order\n",
    "    top_indices = sorted_indices[:top_k]  # Select top-k indices\n",
    "\n",
    "    # Generate pseudo-labels for top-k samples\n",
    "    top_1_labels = np.argmax(similarities[top_indices], axis=1)  # Top-1 labels\n",
    "    second_highest_indices = np.argsort(similarities[top_indices], axis=1)[:, -2]  # Top-2 labels\n",
    "    top_2_labels = second_highest_indices\n",
    "\n",
    "    # Return top embeddings and their pseudo-labels\n",
    "    return embeddings[top_indices], top_1_labels, top_2_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Distillation based LWP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeDistillationLWP:\n",
    "    def __init__(self, lwp_model, distance_metric='cosine', alpha=0.5, beta=0.5):\n",
    "        \"\"\"\n",
    "        Knowledge Distillation-based LWP Model with top-2 pseudo-labeling.\n",
    "        Args:\n",
    "            distance_metric (str): Distance metric to use for LWP (e.g., cosine).\n",
    "            alpha (float): Weighting factor for distillation loss.\n",
    "            beta (float): Weighting factor for top-2 pseudo-label updates.\n",
    "        \"\"\"\n",
    "        self.old_model = LWP(distance_metric='cosine')\n",
    "        self.lwp_model = lwp_model\n",
    "        self.alpha = alpha  # Trade-off between current and old knowledge\n",
    "        self.beta = beta  # Trade-off between top-1 and top-2 pseudo-label prototypes\n",
    "\n",
    "    def fit(self, features, labels=None):\n",
    "        \"\"\"\n",
    "        Fit LWP model with knowledge distillation.\n",
    "        Args:\n",
    "            features (np.array): Embeddings of the current dataset.\n",
    "            labels (np.array): Optional true labels (only for D1).\n",
    "        \"\"\"\n",
    "        # Store the current model as the old model before updating\n",
    "        self.old_model.class_counts = self.lwp_model.class_counts\n",
    "        for i in range(10):\n",
    "            self.old_model.prototypes[i] = self.lwp_model.prototypes[i]\n",
    "        \n",
    "        # Fit the current LWP model to new data\n",
    "        self.lwp_model.fit(features, labels)\n",
    "        print(\"Old Model Prototypes after fit:\", self.old_model.prototypes)\n",
    "        print(\"Class Counts after fit in old:\", self.old_model.class_counts)\n",
    "\n",
    "    \n",
    "    def distillation_loss(self, new_features):\n",
    "        \"\"\"\n",
    "        Compute KL Divergence between old model and current model predictions.\n",
    "        Args:\n",
    "            new_features (np.array): Embeddings of the current dataset.\n",
    "        Returns:\n",
    "            float: Knowledge distillation loss.\n",
    "        \"\"\"\n",
    "        if self.old_model is None:\n",
    "            return 0  # No distillation loss for the first dataset\n",
    "        \n",
    "        # Predictions from the old model\n",
    "        old_predictions = self.old_model.predict_proba(new_features)\n",
    "        print(old_predictions)\n",
    "        # Predictions from the current model\n",
    "        current_predictions = self.lwp_model.predict_proba(new_features)\n",
    "        \n",
    "        # Compute KL divergence\n",
    "        kl_div = np.sum(old_predictions * np.log((old_predictions + 1e-8) / (current_predictions + 1e-8)), axis=1)\n",
    "        return kl_div.mean()\n",
    "\n",
    "    def update_model(self, features):\n",
    "        \"\"\"\n",
    "        Update the LWP model using distillation loss.\n",
    "        Args:\n",
    "            features (np.array): Embeddings of the current dataset.\n",
    "        \"\"\"\n",
    "        if features.size == 0:\n",
    "            print(\"No features available for update. Skipping distillation...\")\n",
    "            return\n",
    "\n",
    "        # Check if prototypes exist\n",
    "        if not self.lwp_model.prototypes:\n",
    "            print(\"No prototypes available. Skipping update...\")\n",
    "            return\n",
    "\n",
    "        centroids = np.vstack([proto for proto in self.lwp_model.prototypes.values()])\n",
    "        top_embeddings, top_1_labels, top_2_labels = select_top_samples(features, centroids)\n",
    "        if top_embeddings.shape[0] != top_1_labels.shape[0]:\n",
    "            print(\"Shape mismatch between top_embeddings and top_1_labels. Skipping...\")\n",
    "            return\n",
    "        # Update prototypes using top-1 and top-2 pseudo-labels\n",
    "        for label in np.unique(top_1_labels):\n",
    "            top_1_samples = top_embeddings[top_1_labels == label]\n",
    "            top_2_samples = top_embeddings[top_2_labels == label]\n",
    "            \n",
    "            if len(top_1_samples) > 0:\n",
    "                new_proto_top1 = top_1_samples.mean(axis=0)\n",
    "                if len(top_2_samples) > 0:\n",
    "                    new_proto_top2 = top_2_samples.mean(axis=0)\n",
    "                    print('shapes are')\n",
    "                    print(new_proto_top1.shape)\n",
    "                    print(new_proto_top2.shape)\n",
    "                    # Combine top-1 and top-2 updates using the beta factor\n",
    "                    self.lwp_model.prototypes[label] = (\n",
    "                        (1 - self.beta) * new_proto_top1 + self.beta * new_proto_top2\n",
    "                    )\n",
    "                else:\n",
    "                    self.lwp_model.prototypes[label] = new_proto_top1\n",
    "        print(f\"feature shape (X): {features.shape}\")\n",
    "        if self.old_model:\n",
    "            print('length is', len(self.old_model.prototypes))\n",
    "            for label, proto in enumerate(self.old_model.prototypes.values()) :\n",
    "                pass\n",
    "                # print(\"For old model\")\n",
    "                # print(f\"Prototype for class {label}: Shape = {proto.shape}\")\n",
    "\n",
    "        \n",
    "        # Align embedding dimensions\n",
    "        # features = features.reshape(features.shape[0], -1)\n",
    "        # print(f\"feature shape (X): {features.shape}\")\n",
    "\n",
    "        if self.old_model:\n",
    "            # Ensure prototype dimensions match features\n",
    "            self.old_model.prototypes = {\n",
    "                label: proto.reshape(-1, features.shape[1])\n",
    "                for label, proto in self.old_model.prototypes.items()\n",
    "        }\n",
    "                    \n",
    "        # Compute distillation loss\n",
    "        print(features.shape)\n",
    "        distillation_loss = self.distillation_loss(features) if self.old_model.class_counts[0] else 0.0\n",
    "        print(f\"Distillation Loss: {distillation_loss:.4f}\")\n",
    "\n",
    "        \n",
    "        # Adjust prototypes based on distillation loss\n",
    "        for label, proto in  enumerate(self.lwp_model.prototypes.values()):\n",
    "            if label in self.old_model.prototypes:\n",
    "                self.lwp_model.prototypes[label] = (\n",
    "                    (1 - self.alpha) * proto + self.alpha * self.old_model.prototypes[label]\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Label {label} not found in old model prototypes. Skipping...\")\n",
    "\n",
    "    def predict(self, features):\n",
    "        \"\"\"\n",
    "        Predict pseudo-labels for the given features.\n",
    "        Args:\n",
    "            features (np.array): Embeddings of the data points.\n",
    "        Returns:\n",
    "            np.array: Predicted labels.\n",
    "        \"\"\"\n",
    "        return self.lwp_model.predict(features)\n",
    "    \n",
    "    def predict_proba(self, features):\n",
    "        \"\"\"\n",
    "        Predict probabilities (normalized distances to prototypes).\n",
    "        Args:\n",
    "            features (np.array): Embeddings of the data points.\n",
    "        Returns:\n",
    "            np.array: Predicted probabilities for each class.\n",
    "        \"\"\"\n",
    "        distances = []\n",
    "        for feature in features:\n",
    "            dist = {\n",
    "                label: self.lwp_model.distance_fn(feature, proto)\n",
    "                for label, proto in self.lwp_model.prototypes\n",
    "            }\n",
    "            # Convert distances to probabilities\n",
    "            prob = np.exp(-np.array(list(dist.values())))\n",
    "            prob /= prob.sum()\n",
    "            distances.append(prob)\n",
    "        return np.vstack(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process a dataset using kNN with top-2 pseudo-labels and knowledge distillation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model\n",
    "def evaluate_on_eval_embeddings(embed_dir, dataset_idx, model, ground_truth=None):\n",
    "    embed_path = os.path.join(embed_dir, f'eval_embeds_{dataset_idx}.pt')\n",
    "    eval_embeddings = torch.load(embed_path, weights_only=False)\n",
    "\n",
    "    print(f\"Evaluating on dataset {dataset_idx}...\")\n",
    "    predicted_labels = model.predict(eval_embeddings)\n",
    "\n",
    "    if ground_truth is not None:\n",
    "        accuracy = accuracy_score(ground_truth, predicted_labels)\n",
    "        report = classification_report(ground_truth, predicted_labels, zero_division=0)\n",
    "        print(f\"Accuracy on eval set {dataset_idx}: {accuracy * 100:.2f}%\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(report)\n",
    "        return {\"accuracy\": accuracy, \"report\": report}\n",
    "    else:\n",
    "        print(f\"Predictions on eval set {dataset_idx}: {predicted_labels[:10]}...\")\n",
    "        return {\"predicted_labels\": predicted_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 768) (2500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88067/54649724.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_embeddings = torch.load(train_embed_path)\n",
      "/tmp/ipykernel_88067/54649724.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  eval_embeddings = torch.load(eval_embed_path)\n",
      "/tmp/ipykernel_88067/54649724.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(train_path)\n"
     ]
    }
   ],
   "source": [
    "# Directories for embeddings\n",
    "part_one_embed_dir = 'part_1_vit_embeds'\n",
    "part_two_embed_dir = 'part_2_vit_embeds'\n",
    "\n",
    "# Load D1 embeddings and targets\n",
    "train_embed_path = os.path.join(part_one_embed_dir, 'train_embeds_1.pt')\n",
    "eval_embed_path = os.path.join(part_one_embed_dir, 'eval_embeds_1.pt')\n",
    "train_embeddings = torch.load(train_embed_path)\n",
    "eval_embeddings = torch.load(eval_embed_path)\n",
    "train_path = os.path.join('dataset', 'part_one_dataset', 'train_data', '1_train_data.tar.pth')\n",
    "data = torch.load(train_path)\n",
    "targets = data['targets']\n",
    "\n",
    "# Initialize and fit LWP model\n",
    "lwp_model = LWP(distance_metric='cosine')\n",
    "lwp_model.fit(train_embeddings, targets)\n",
    "print(train_embeddings.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset 3 with kNN...\n",
      "Loaded embeddings for dataset 3: (2500, 768)\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Using k=5 for kNN classification (based on top 1250 embeddings)...\n",
      "Dataset 3: Assigned pseudo-labels using kNN\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2513",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m all_pseudo_labels \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(embeddings)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Assigned pseudo-labels using kNN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[43mlwp_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_pseudo_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Update prototypes using top-2 pseudo-labels\u001b[39;00m\n\u001b[1;32m     49\u001b[0m kd_lwp_model\u001b[38;5;241m.\u001b[39mupdate_model(embeddings)\n",
      "Cell \u001b[0;32mIn[92], line 43\u001b[0m, in \u001b[0;36mLWP.fit\u001b[0;34m(self, features, labels)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_counts[label] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(samples)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_counts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(samples)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprototypes[label] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     45\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_counts[label] \u001b[38;5;241m-\u001b[39m num_samples) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_counts[label] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprototypes[label] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     46\u001b[0m         num_samples \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_counts[label] \u001b[38;5;241m*\u001b[39m samples\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     47\u001b[0m     )\n",
      "\u001b[0;31mKeyError\u001b[0m: 2513"
     ]
    }
   ],
   "source": [
    "kd_lwp_model = KnowledgeDistillationLWP(lwp_model,alpha=0.5)\n",
    "\n",
    "# Process D2-D10 with kNN and pseudo-labeling\n",
    "for i in range(2, 11):\n",
    "    dataset_idx = i\n",
    "    k = 5\n",
    "    embed_dir = part_one_embed_dir\n",
    "    top_percentage = 0.5\n",
    "    \"\"\"\n",
    "    Process the dataset using kNN and pseudo-labeling.\n",
    "    \n",
    "    Args:\n",
    "        embed_dir (str): Directory containing embeddings.\n",
    "        dataset_idx (int): Dataset index.\n",
    "        lwp_model (LWP): LWP model instance.\n",
    "        kd_lwp_model (KD-LWP): KD-LWP model instance.\n",
    "        k (int): Number of neighbors for kNN.\n",
    "        top_percentage (float): Percentage of samples to select for pseudo-labeling (0 < top_percentage <= 1).\n",
    "    \"\"\"\n",
    "    print(f\"Processing dataset {dataset_idx} with kNN...\")\n",
    "    # Load embeddings\n",
    "    embed_path = os.path.join(embed_dir, f'train_embeds_{dataset_idx}.pt')\n",
    "    embeddings = torch.load(embed_path, weights_only=False)\n",
    "    print(f\"Loaded embeddings for dataset {dataset_idx}: {embeddings.shape}\")\n",
    "    \n",
    "    if embeddings.size == 0:\n",
    "        print(f\"Dataset {dataset_idx} contains no embeddings. Skipping...\")\n",
    "        break\n",
    "\n",
    "    # Compute centroids (prototypes)\n",
    "    if not lwp_model.prototypes:\n",
    "        print(f\"No prototypes available in LWP model for dataset {dataset_idx}. Skipping...\")\n",
    "        break\n",
    "    # compute prototypes(centroids)\n",
    "    centroids = np.vstack([proto for proto in sorted(lwp_model.prototypes.items())])\n",
    "    # Select top 50% samples based on cosine similarity to centroids\n",
    "    top_embeddings, top_1_labels, top_2_labels = select_top_samples(embeddings, centroids, top_percentage=top_percentage)\n",
    "    # Ensure k is not greater than the number of top embeddings\n",
    "    k = min(k, len(top_embeddings))\n",
    "    print(f\"Using k={k} for kNN classification (based on top {len(top_embeddings)} embeddings)...\")\n",
    "    \n",
    "    \n",
    "    # Train kNN on the top samples\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "    knn.fit(top_embeddings, top_1_labels)\n",
    "\n",
    "    # Use kNN to assign pseudo-labels for all embeddings\n",
    "    all_pseudo_labels = knn.predict(embeddings)\n",
    "    print(f\"Dataset {dataset_idx}: Assigned pseudo-labels using kNN\")\n",
    "    lwp_model.fit(embeddings, all_pseudo_labels)\n",
    "\n",
    "    # Update prototypes using top-2 pseudo-labels\n",
    "    kd_lwp_model.update_model(embeddings)\n",
    "    kd_lwp_model.fit(embeddings)\n",
    "    # # Update prototypes (class centroids) with kNN pseudo-labeled samples\n",
    "    # for label in np.unique(all_pseudo_labels):\n",
    "    #     class_embeddings = embeddings[all_pseudo_labels == label]\n",
    "    #     if class_embeddings.size > 0:\n",
    "    #         centroid = class_embeddings.mean(axis=0)\n",
    "    #         lwp_model.prototypes[label] = centroid\n",
    "\n",
    "    print(f\"Dataset {dataset_idx}: Updated prototypes for classes {list(kd_lwp_model.lwp_model.prototypes.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on D1 (with ground truth)\n",
    "eval_labels_path = os.path.join('dataset', 'part_one_dataset', 'eval_data', '1_eval_data.tar.pth')\n",
    "eval_data = torch.load(eval_labels_path)\n",
    "eval_ground_truth = eval_data['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_ground_truth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate_on_eval_embeddings(part_one_embed_dir, dataset_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, model\u001b[38;5;241m=\u001b[39mlwp_model, ground_truth\u001b[38;5;241m=\u001b[39m\u001b[43meval_ground_truth\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_ground_truth' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_on_eval_embeddings(part_one_embed_dir, dataset_idx=1, model=lwp_model, ground_truth=eval_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on D2-D10\n",
    "for i in range(2, 11):\n",
    "    evaluate_on_eval_embeddings(part_one_embed_dir, dataset_idx=i, model=lwp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process D11-D20 (unlabeled datasets) with knowledge distillation\n",
    "for i in range(11, 21):\n",
    "    train_path = os.path.join(part_two_embed_dir, f'train_embeds_{i}.pt')\n",
    "    print(f\"Processing dataset D{i} from {train_path}...\")\n",
    "    \n",
    "    # Load train embeddings\n",
    "    train_embeddings = torch.load(train_path).numpy()\n",
    "    \n",
    "    # Perform knowledge distillation-based learning\n",
    "    kd_lwp_model.update_model(train_embeddings)\n",
    "    kd_lwp_model.fit(train_embeddings)\n",
    "    \n",
    "    # Evaluate or predict on eval set if needed\n",
    "    eval_path = os.path.join(part_two_embed_dir, f'eval_embeds_{i}.pt')\n",
    "    eval_embeddings = torch.load(eval_path, weights_only=False).numpy()\n",
    "    predictions = kd_lwp_model.predict(eval_embeddings)\n",
    "    print(f\"Pseudo-labels for eval set of D{i}: {predictions[:10]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on D11-D20 (unlabeled datasets)\n",
    "for i in range(11, 21):\n",
    "    evaluate_on_eval_embeddings(part_two_embed_dir, dataset_idx=i, model=lwp_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "771",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
