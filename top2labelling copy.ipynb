{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('dataset', 'part_one_dataset', 'train_data')\n",
    "eval_dir = os.path.join('dataset', 'part_one_dataset', 'eval_data')\n",
    "train_path = os.path.join(train_dir, '1_train_data.tar.pth')\n",
    "eval_path = os.path.join(eval_dir, '1_eval_data.tar.pth')\n",
    "\n",
    "t = torch.load(train_path, weights_only = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic LWP Model using Distance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances, manhattan_distances\n",
    "\n",
    "class LWP:\n",
    "    \"\"\"Learning Vector Prototypes with configurable distance function\"\"\"\n",
    "    \n",
    "    DISTANCE_FUNCTIONS = {\n",
    "        'euclidean': lambda x, y: np.linalg.norm(x - y),\n",
    "        'cosine': lambda x, y: cosine_distances(x.reshape(1, -1), y.reshape(1, -1))[0][0],\n",
    "        'manhattan': lambda x, y: manhattan_distances(x.reshape(1, -1), y.reshape(1, -1))[0][0],\n",
    "        'minkowski': lambda x, y, p=2: np.power(np.sum(np.power(np.abs(x - y), p)), 1/p)\n",
    "    }\n",
    "    \n",
    "    def __init__(self, distance_metric='euclidean', **distance_params):\n",
    "        \"\"\"\n",
    "            distance_params (dict): Additional parameters for the distance function\n",
    "        \"\"\"\n",
    "        self.prototypes = {}\n",
    "        self.class_counts = {i: 0 for i in range(10)}\n",
    "        \n",
    "        if callable(distance_metric):\n",
    "            self.distance_fn = distance_metric\n",
    "        elif distance_metric in self.DISTANCE_FUNCTIONS:\n",
    "            if distance_metric == 'minkowski':\n",
    "                p = distance_params.get('p', 2)\n",
    "                self.distance_fn = lambda x, y: self.DISTANCE_FUNCTIONS[distance_metric](x, y, p)\n",
    "            else:\n",
    "                self.distance_fn = self.DISTANCE_FUNCTIONS[distance_metric]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown distance metric: {distance_metric}. \" \n",
    "                           f\"Available metrics: {list(self.DISTANCE_FUNCTIONS.keys())}\")\n",
    "\n",
    "    def fit(self, features, labels):\n",
    "        unique_labels = np.unique(labels)\n",
    "        for label in unique_labels:\n",
    "            samples = features[labels == label]\n",
    "            num_samples = len(samples)\n",
    "            \n",
    "            if label not in self.prototypes:  # Original condition was: if label not in self.prototypes\n",
    "                self.prototypes[label] = samples.mean(axis=0)\n",
    "                self.class_counts[label] = len(samples)\n",
    "            else:\n",
    "                self.class_counts[label] += len(samples)\n",
    "                self.prototypes[label] = (\n",
    "                    (self.class_counts[label] - num_samples) / self.class_counts[label] * self.prototypes[label] +\n",
    "                    num_samples / self.class_counts[label] * samples.mean(axis=0)\n",
    "                )\n",
    "    \n",
    "            \n",
    "    \n",
    "\n",
    "    def predict(self, features):\n",
    "        preds = []\n",
    "        for feature in features:\n",
    "            distances = {\n",
    "                label: self.distance_fn(feature, proto)\n",
    "                for label, proto in self.prototypes.items()\n",
    "            }\n",
    "            preds.append(min(distances, key=distances.get))\n",
    "        return np.array(preds)\n",
    "    \n",
    "    def predict_proba(self, features):\n",
    "        \"\"\"\n",
    "        Predict probabilities (normalized distances to prototypes).\n",
    "        Args:\n",
    "            features (np.array): Embeddings of the data points.\n",
    "        Returns:\n",
    "            np.array: Probabilities for each class.\n",
    "        \"\"\"\n",
    "        prob_list = []\n",
    "        for feature in features:\n",
    "            # Calculate distances to all prototypes\n",
    "            \n",
    "            # for label, proto in enumerate(self.prototypes.values()) :\n",
    "            #     print('shape of proto is' , proto.shape)\n",
    "            distances = {\n",
    "                label: self.distance_fn(feature, proto) for label, proto in enumerate(self.prototypes.values())\n",
    "            }\n",
    "            \n",
    "            # Convert distances to probabilities\n",
    "            exp_neg_distances = np.exp(-np.array(list(distances.values())))  # Exponential of negative distances\n",
    "            probabilities = exp_neg_distances / exp_neg_distances.sum()  # Normalize to sum to 1\n",
    "            \n",
    "            prob_list.append(probabilities)\n",
    "        \n",
    "        return np.vstack(prob_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute cosine similarity and select top samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_samples(embeddings, centroids, top_percentage=0.5):\n",
    "    \"\"\"\n",
    "    Select top-k% samples with highest cosine similarity to centroids\n",
    "    and include top-2 pseudo-labels.\n",
    "    Args:\n",
    "        embeddings (np.array): The data embeddings.\n",
    "        centroids (np.array): Prototypes or centroids for each class.\n",
    "        top_percentage (float): Percentage of top samples to select (0 < top_percentage <= 1).\n",
    "    Returns:\n",
    "        tuple: Top-k% embeddings, top-1 pseudo-labels, and top-2 pseudo-labels.\n",
    "    \"\"\"\n",
    "    if not (0 < top_percentage <= 1):\n",
    "        raise ValueError(\"top_percentage must be between 0 and 1.\")\n",
    "\n",
    "    # Compute similarity scores\n",
    "    similarities = cosine_similarity(embeddings, centroids)\n",
    "\n",
    "    # Compute the number of samples to select (50% of total embeddings)\n",
    "    total_samples = embeddings.shape[0]\n",
    "    top_k = int(total_samples * top_percentage)\n",
    "    print(f\"Selecting top {top_k} samples out of {total_samples} (percentage: {top_percentage * 100}%)...\")\n",
    "\n",
    "    # Find top-k samples with the highest cosine similarity to centroids\n",
    "    max_similarities = np.max(similarities, axis=1)\n",
    "    sorted_indices = np.argsort(max_similarities)[::-1]  # Sort by similarity in descending order\n",
    "    top_indices = sorted_indices[:top_k]  # Select top-k indices\n",
    "\n",
    "    # Generate pseudo-labels for top-k samples\n",
    "    top_1_labels = np.argmax(similarities[top_indices], axis=1)  # Top-1 labels\n",
    "    second_highest_indices = np.argsort(similarities[top_indices], axis=1)[:, -2]  # Top-2 labels\n",
    "    top_2_labels = second_highest_indices\n",
    "\n",
    "    # Return top embeddings and their pseudo-labels\n",
    "    return embeddings[top_indices], top_1_labels, top_2_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Distillation based LWP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeDistillationLWP:\n",
    "    def __init__(self, lwp_model, distance_metric='cosine', alpha=0.5, beta=0.5):\n",
    "        \"\"\"\n",
    "        Knowledge Distillation-based LWP Model with top-2 pseudo-labeling.\n",
    "        Args:\n",
    "            distance_metric (str): Distance metric to use for LWP (e.g., cosine).\n",
    "            alpha (float): Weighting factor for distillation loss.\n",
    "            beta (float): Weighting factor for top-2 pseudo-label updates.\n",
    "        \"\"\"\n",
    "        self.old_model = LWP(distance_metric=distance_metric)\n",
    "        self.lwp_model = lwp_model\n",
    "        self.alpha = alpha  # Trade-off between current and old knowledge\n",
    "        self.beta = beta  # Trade-off between top-1 and top-2 pseudo-label prototypes\n",
    "\n",
    "    def fit(self, features, labels):\n",
    "        \"\"\"\n",
    "        Fit LWP model with knowledge distillation.\n",
    "        Args:\n",
    "            features (np.array): Embeddings of the current dataset.\n",
    "            labels (np.array): Optional true labels (only for D1).\n",
    "        \"\"\"\n",
    "        # Store the current model as the old model before updating\n",
    "        self.old_model.class_counts = self.lwp_model.class_counts\n",
    "        for i in range(10):\n",
    "            self.old_model.prototypes[i] = self.lwp_model.prototypes[i]\n",
    "        \n",
    "        # Fit the current LWP model to new data\n",
    "        self.lwp_model.fit(features, labels)\n",
    "        # print(\"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAa\")\n",
    "        # print(self.old_model.prototypes.keys())\n",
    "        # print(np.unique(labels))\n",
    "        # print(self.lwp_model.prototypes.keys())\n",
    "        # print(\"Old Model Prototypes after fit:\", self.old_model.prototypes)\n",
    "        print(\"Class Counts after fit in old:\", self.old_model.class_counts)\n",
    "\n",
    "    \n",
    "    def distillation_loss(self, new_features):\n",
    "        \"\"\"\n",
    "        Compute KL Divergence between old model and current model predictions.\n",
    "        Args:\n",
    "            new_features (np.array): Embeddings of the current dataset.\n",
    "        Returns:\n",
    "            float: Knowledge distillation loss.\n",
    "        \"\"\"\n",
    "        if self.old_model is None:\n",
    "            return 0  # No distillation loss for the first dataset\n",
    "        \n",
    "        # Predictions from the old model\n",
    "        old_predictions = self.old_model.predict_proba(new_features)\n",
    "        # print(old_predictions)\n",
    "        # Predictions from the current model\n",
    "        current_predictions = self.lwp_model.predict_proba(new_features)\n",
    "        \n",
    "        # Compute KL divergence\n",
    "        kl_div = np.sum(old_predictions * np.log((old_predictions + 1e-8) / (current_predictions + 1e-8)), axis=1)\n",
    "        return kl_div.mean()\n",
    "\n",
    "    def update_model(self, features):\n",
    "        \"\"\"\n",
    "        Update the LWP model using distillation loss.\n",
    "        Args:\n",
    "            features (np.array): Embeddings of the current dataset.\n",
    "        \"\"\"\n",
    "        if features.size == 0:\n",
    "            print(\"No features available for update. Skipping distillation...\")\n",
    "            return\n",
    "\n",
    "        # Check if prototypes exist\n",
    "        if not self.lwp_model.prototypes:\n",
    "            print(\"No prototypes available. Skipping update...\")\n",
    "            return\n",
    "        # print(features.shape)\n",
    "        # return\n",
    "        centroids = np.vstack([proto for proto in self.lwp_model.prototypes.values()])\n",
    "        top_embeddings, top_1_labels, top_2_labels = select_top_samples(features, centroids)\n",
    "        # print(\"why do i exist:\", np.unique(top_1_labels))\n",
    "        if top_embeddings.shape[0] != top_1_labels.shape[0]:\n",
    "            print(\"Shape mismatch between top_embeddings and top_1_labels. Skipping...\")\n",
    "            return\n",
    "        # Update prototypes using top-1 and top-2 pseudo-labels\n",
    "        iterations = 0\n",
    "        for label in np.unique(top_1_labels):\n",
    "            iterations += 1\n",
    "            top_1_samples = top_embeddings[top_1_labels == label]\n",
    "            top_2_samples = top_embeddings[top_2_labels == label]\n",
    "            # print(\"hi\")\n",
    "            if len(top_1_samples) > 0:\n",
    "                new_proto_top1 = top_1_samples.mean(axis=0)\n",
    "                if len(top_2_samples) > 0:\n",
    "                    new_proto_top2 = top_2_samples.mean(axis=0)\n",
    "                    # print('shapes are')\n",
    "                    # print(new_proto_top1.shape)\n",
    "                    # print(new_proto_top2.shape)\n",
    "                    # Combine top-1 and top-2 updates using the beta factor\n",
    "                    self.lwp_model.prototypes[label] = (\n",
    "                        (1 - self.beta) * new_proto_top1 + self.beta * new_proto_top2\n",
    "                    )\n",
    "                else:\n",
    "                    self.lwp_model.prototypes[label] = new_proto_top1\n",
    "        # print(f\"feature shape (X): {features.shape}\")\n",
    "\n",
    "        if self.old_model:\n",
    "            # Ensure prototype dimensions match features\n",
    "            self.old_model.prototypes = {\n",
    "                label: proto.reshape(-1, features.shape[1])\n",
    "                for label, proto in self.old_model.prototypes.items()\n",
    "        }\n",
    "                    \n",
    "        # Compute distillation loss\n",
    "        # print(self.old_model.prototypes)\n",
    "        distillation_loss = self.distillation_loss(features) if self.old_model.class_counts[0] else 0.0\n",
    "        print(f\"Distillation Loss: {distillation_loss:.4f}\")\n",
    "\n",
    "        \n",
    "        # Adjust prototypes based on distillation loss\n",
    "        \n",
    "        for label, proto in  enumerate(self.lwp_model.prototypes.values()):\n",
    "            # print(\"i'm in love with the shape of X\", label)\n",
    "            if label in self.old_model.prototypes:\n",
    "                self.lwp_model.prototypes[label] = (\n",
    "                    (1 - self.alpha) * proto + self.alpha * self.old_model.prototypes[label]\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Label {label} not found in old model prototypes. Skipping...\")\n",
    "\n",
    "    def predict(self, features):\n",
    "        \"\"\"\n",
    "        Predict pseudo-labels for the given features.\n",
    "        Args:\n",
    "            features (np.array): Embeddings of the data points.\n",
    "        Returns:\n",
    "            np.array: Predicted labels.\n",
    "        \"\"\"\n",
    "        return self.lwp_model.predict(features)\n",
    "    \n",
    "    def predict_proba(self, features):\n",
    "        \"\"\"\n",
    "        Predict probabilities (normalized distances to prototypes).\n",
    "        Args:\n",
    "            features (np.array): Embeddings of the data points.\n",
    "        Returns:\n",
    "            np.array: Predicted probabilities for each class.\n",
    "        \"\"\"\n",
    "        distances = []\n",
    "        for feature in features:\n",
    "            dist = {\n",
    "                label: self.lwp_model.distance_fn(feature, proto)\n",
    "                for label, proto in self.lwp_model.prototypes\n",
    "            }\n",
    "            # Convert distances to probabilities\n",
    "            prob = np.exp(-np.array(list(dist.values())))\n",
    "            prob /= prob.sum()\n",
    "            distances.append(prob)\n",
    "        return np.vstack(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process a dataset using kNN with top-2 pseudo-labels and knowledge distillation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model\n",
    "def evaluate_on_eval_embeddings(embed_dir, dataset_idx, model, ground_truth=None):\n",
    "    embed_path = os.path.join(embed_dir, f'eval_embeds_{dataset_idx}.pt')\n",
    "    eval_embeddings = torch.load(embed_path, weights_only=False)\n",
    "\n",
    "    print(f\"Evaluating on dataset {dataset_idx}...\")\n",
    "    predicted_labels = model.predict(eval_embeddings)\n",
    "\n",
    "    if ground_truth is not None:\n",
    "        accuracy = accuracy_score(ground_truth, predicted_labels)\n",
    "        report = classification_report(ground_truth, predicted_labels, zero_division=0)\n",
    "        print(f\"Accuracy on eval set {dataset_idx}: {accuracy * 100:.2f}%\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(report)\n",
    "        return {\"accuracy\": accuracy, \"report\": report}\n",
    "    else:\n",
    "        print(f\"Predictions on eval set {dataset_idx}: {predicted_labels[:10]}...\")\n",
    "        return {\"predicted_labels\": predicted_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for embeddings\n",
    "part_one_embed_dir = 'part_1_vit_embeds'\n",
    "part_two_embed_dir = 'part_2_vit_embeds'\n",
    "\n",
    "models = []\n",
    "\n",
    "# Load D1 embeddings and targets\n",
    "train_embed_path = os.path.join(part_one_embed_dir, 'train_embeds_1.pt')\n",
    "eval_embed_path = os.path.join(part_one_embed_dir, 'eval_embeds_1.pt')\n",
    "train_embeddings = torch.load(train_embed_path, weights_only=False)\n",
    "eval_embeddings = torch.load(eval_embed_path, weights_only=False)\n",
    "train_path = os.path.join('dataset', 'part_one_dataset', 'train_data', '1_train_data.tar.pth')\n",
    "data = torch.load(train_path, weights_only=False)\n",
    "targets = data['targets']\n",
    "\n",
    "# Initialize and fit LWP model\n",
    "lwp_model = LWP(distance_metric='cosine')\n",
    "lwp_model.fit(train_embeddings, targets)\n",
    "# print(train_embeddings.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset 2 with kNN...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0000\n",
      "Label 0 not found in old model prototypes. Skipping...\n",
      "Label 1 not found in old model prototypes. Skipping...\n",
      "Label 2 not found in old model prototypes. Skipping...\n",
      "Label 3 not found in old model prototypes. Skipping...\n",
      "Label 4 not found in old model prototypes. Skipping...\n",
      "Label 5 not found in old model prototypes. Skipping...\n",
      "Label 6 not found in old model prototypes. Skipping...\n",
      "Label 7 not found in old model prototypes. Skipping...\n",
      "Label 8 not found in old model prototypes. Skipping...\n",
      "Label 9 not found in old model prototypes. Skipping...\n",
      "Class Counts after fit in old: {0: 486, 1: 507, 2: 407, 3: 503, 4: 542, 5: 433, 6: 516, 7: 583, 8: 499, 9: 524}\n",
      "Dataset 2: Updated prototypes for classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Processing dataset 3 with kNN...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0001\n",
      "Class Counts after fit in old: {0: 747, 1: 750, 2: 558, 3: 711, 4: 855, 5: 671, 6: 795, 7: 876, 8: 757, 9: 780}\n",
      "Dataset 3: Updated prototypes for classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Processing dataset 4 with kNN...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0001\n",
      "Class Counts after fit in old: {0: 994, 1: 1013, 2: 713, 3: 934, 4: 1126, 5: 874, 6: 1062, 7: 1202, 8: 1000, 9: 1082}\n",
      "Dataset 4: Updated prototypes for classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Processing dataset 5 with kNN...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0001\n",
      "Class Counts after fit in old: {0: 1240, 1: 1281, 2: 852, 3: 1165, 4: 1430, 5: 1066, 6: 1312, 7: 1531, 8: 1244, 9: 1379}\n",
      "Dataset 5: Updated prototypes for classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Processing dataset 6 with kNN...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0000\n",
      "Class Counts after fit in old: {0: 1478, 1: 1502, 2: 1014, 3: 1396, 4: 1732, 5: 1307, 6: 1571, 7: 1861, 8: 1480, 9: 1659}\n",
      "Dataset 6: Updated prototypes for classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Processing dataset 7 with kNN...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0000\n",
      "Class Counts after fit in old: {0: 1720, 1: 1737, 2: 1161, 3: 1605, 4: 2064, 5: 1490, 6: 1818, 7: 2212, 8: 1758, 9: 1935}\n",
      "Dataset 7: Updated prototypes for classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Processing dataset 8 with kNN...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0000\n",
      "Class Counts after fit in old: {0: 1967, 1: 1987, 2: 1343, 3: 1832, 4: 2349, 5: 1720, 6: 2059, 7: 2524, 8: 2000, 9: 2219}\n",
      "Dataset 8: Updated prototypes for classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Processing dataset 9 with kNN...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0000\n",
      "Class Counts after fit in old: {0: 2203, 1: 2251, 2: 1489, 3: 2056, 4: 2668, 5: 1922, 6: 2307, 7: 2829, 8: 2263, 9: 2512}\n",
      "Dataset 9: Updated prototypes for classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Processing dataset 10 with kNN...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0000\n",
      "Class Counts after fit in old: {0: 2443, 1: 2491, 2: 1641, 3: 2284, 4: 2963, 5: 2164, 6: 2550, 7: 3160, 8: 2512, 9: 2792}\n",
      "Dataset 10: Updated prototypes for classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "import copy \n",
    "\n",
    "lwp_model = LWP(distance_metric='cosine')\n",
    "lwp_model.fit(train_embeddings, targets)\n",
    "models.append(copy.deepcopy(lwp_model))\n",
    "kd_lwp_model = KnowledgeDistillationLWP(copy.deepcopy(lwp_model),alpha=0.5)\n",
    "\n",
    "# Process D2-D10 with kNN and pseudo-labeling\n",
    "for i in range(2, 11):\n",
    "    dataset_idx = i\n",
    "    k = 5\n",
    "    embed_dir = part_one_embed_dir\n",
    "    top_percentage = 0.5\n",
    "    \"\"\"\n",
    "    Process the dataset using kNN and pseudo-labeling.\n",
    "    \n",
    "    Args:\n",
    "        embed_dir (str): Directory containing embeddings.\n",
    "        dataset_idx (int): Dataset index.\n",
    "        lwp_model (LWP): LWP model instance.\n",
    "        kd_lwp_model (KD-LWP): KD-LWP model instance.\n",
    "        k (int): Number of neighbors for kNN.\n",
    "        top_percentage (float): Percentage of samples to select for pseudo-labeling (0 < top_percentage <= 1).\n",
    "    \"\"\"\n",
    "    print(f\"Processing dataset {dataset_idx} with kNN...\")\n",
    "    # Load embeddings\n",
    "    embed_path = os.path.join(embed_dir, f'train_embeds_{dataset_idx}.pt')\n",
    "    embeddings = torch.load(embed_path, weights_only=False)\n",
    "    # print(f\"Loaded embeddings for dataset {dataset_idx}: {embeddings.shape}\")\n",
    "    \n",
    "    if embeddings.size == 0:\n",
    "        print(f\"Dataset {dataset_idx} contains no embeddings. Skipping...\")\n",
    "        break\n",
    "\n",
    "    # Compute centroids (prototypes)\n",
    "    if not lwp_model.prototypes:\n",
    "        print(f\"No prototypes available in LWP model for dataset {dataset_idx}. Skipping...\")\n",
    "        break\n",
    "    # compute prototypes(centroids)\n",
    "    centroids = np.vstack([proto for proto in lwp_model.prototypes.values()])\n",
    "    # Select top 50% samples based on cosine similarity to centroids\n",
    "    top_embeddings, top_1_labels, top_2_labels = select_top_samples(embeddings, centroids, top_percentage=top_percentage)\n",
    "    # Ensure k is not greater than the number of top embeddings\n",
    "    # print(top_embeddings.shape, top_1_labels.shape, top_2_labels.shape)\n",
    "    k = min(k, len(top_embeddings))\n",
    "    # print(f\"Using k={k} for kNN classification (based on top {len(top_embeddings)} embeddings)...\")\n",
    "    \n",
    "    # Train kNN on the top samples\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "    knn.fit(top_embeddings, top_1_labels)\n",
    "\n",
    "    # Use kNN to assign pseudo-labels for all embeddings\n",
    "    all_pseudo_labels = knn.predict(embeddings)\n",
    "    # print(f\"Dataset {dataset_idx}: Assigned pseudo-labels using kNN\")\n",
    "    lwp_model.fit(embeddings, all_pseudo_labels)\n",
    "\n",
    "    # Update prototypes using top-2 pseudo-labels\n",
    "    kd_lwp_model.update_model(embeddings)\n",
    "    # print(\"why so sad: \", kd_lwp_model.lwp_model.prototypes.keys())\n",
    "    kd_lwp_model.fit(embeddings, all_pseudo_labels)\n",
    "    # # Update prototypes (class centroids) with kNN pseudo-labeled samples\n",
    "    # for label in np.unique(all_pseudo_labels):\n",
    "    #     class_embeddings = embeddings[all_pseudo_labels == label]\n",
    "    #     if class_embeddings.size > 0:\n",
    "    #         centroid = class_embeddings.mean(axis=0)\n",
    "    #         lwp_model.prototypes[label] = centroid\n",
    "\n",
    "    models.append(copy.deepcopy(kd_lwp_model))\n",
    "    \n",
    "    print(f\"Dataset {dataset_idx}: Updated prototypes for classes {list(kd_lwp_model.lwp_model.prototypes.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANUSHKA SINGH\\AppData\\Local\\Temp\\ipykernel_24724\\2575434816.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  eval_data = torch.load(eval_labels_path)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on D1 (with ground truth)\n",
    "eval_labels_path = os.path.join('dataset', 'part_one_dataset', 'eval_data', '1_eval_data.tar.pth')\n",
    "eval_data = torch.load(eval_labels_path)\n",
    "eval_ground_truth = eval_data['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on dataset 1...\n",
      "Accuracy on eval set 1: 88.20%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91       252\n",
      "           1       0.90      0.95      0.92       217\n",
      "           2       0.98      0.70      0.82       264\n",
      "           3       0.82      0.85      0.83       242\n",
      "           4       0.77      0.90      0.83       257\n",
      "           5       0.85      0.85      0.85       252\n",
      "           6       0.95      0.93      0.94       269\n",
      "           7       0.83      0.88      0.86       233\n",
      "           8       0.95      0.93      0.94       266\n",
      "           9       0.89      0.95      0.92       248\n",
      "\n",
      "    accuracy                           0.88      2500\n",
      "   macro avg       0.89      0.88      0.88      2500\n",
      "weighted avg       0.89      0.88      0.88      2500\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.882,\n",
       " 'report': '              precision    recall  f1-score   support\\n\\n           0       0.93      0.88      0.91       252\\n           1       0.90      0.95      0.92       217\\n           2       0.98      0.70      0.82       264\\n           3       0.82      0.85      0.83       242\\n           4       0.77      0.90      0.83       257\\n           5       0.85      0.85      0.85       252\\n           6       0.95      0.93      0.94       269\\n           7       0.83      0.88      0.86       233\\n           8       0.95      0.93      0.94       266\\n           9       0.89      0.95      0.92       248\\n\\n    accuracy                           0.88      2500\\n   macro avg       0.89      0.88      0.88      2500\\nweighted avg       0.89      0.88      0.88      2500\\n'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_on_eval_embeddings(part_one_embed_dir, dataset_idx=1, model=lwp_model, ground_truth=eval_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on dataset 2...\n",
      "Accuracy on eval set 2: 66.40%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       271\n",
      "           1       0.31      0.29      0.30       261\n",
      "           2       0.62      0.45      0.52       267\n",
      "           3       0.68      0.66      0.67       258\n",
      "           4       0.74      0.84      0.79       236\n",
      "           5       0.59      0.87      0.71       212\n",
      "           6       0.74      0.69      0.71       250\n",
      "           7       0.87      0.73      0.80       252\n",
      "           8       0.96      0.89      0.92       258\n",
      "           9       0.32      0.38      0.35       235\n",
      "\n",
      "    accuracy                           0.66      2500\n",
      "   macro avg       0.67      0.67      0.66      2500\n",
      "weighted avg       0.67      0.66      0.66      2500\n",
      "\n",
      "Evaluating on dataset 3...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m11\u001b[39m):\n\u001b[0;32m      3\u001b[0m     t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpart_one_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_eval_data.tar.pth\u001b[39m\u001b[38;5;124m'\u001b[39m) ,weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mevaluate_on_eval_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart_one_embed_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkd_lwp_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtargets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m, in \u001b[0;36mevaluate_on_eval_embeddings\u001b[1;34m(embed_dir, dataset_idx, model, ground_truth)\u001b[0m\n\u001b[0;32m      4\u001b[0m eval_embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(embed_path, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating on dataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ground_truth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(ground_truth, predicted_labels)\n",
      "Cell \u001b[1;32mIn[5], line 134\u001b[0m, in \u001b[0;36mKnowledgeDistillationLWP.predict\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, features):\n\u001b[0;32m    127\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    Predict pseudo-labels for the given features.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        np.array: Predicted labels.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlwp_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 55\u001b[0m, in \u001b[0;36mLWP.predict\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     53\u001b[0m preds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m---> 55\u001b[0m     distances \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     56\u001b[0m         label: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistance_fn(feature, proto)\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m label, proto \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprototypes\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     58\u001b[0m     }\n\u001b[0;32m     59\u001b[0m     preds\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mmin\u001b[39m(distances, key\u001b[38;5;241m=\u001b[39mdistances\u001b[38;5;241m.\u001b[39mget))\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(preds)\n",
      "Cell \u001b[1;32mIn[3], line 56\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     53\u001b[0m preds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[0;32m     55\u001b[0m     distances \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m---> 56\u001b[0m         label: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m label, proto \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprototypes\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     58\u001b[0m     }\n\u001b[0;32m     59\u001b[0m     preds\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mmin\u001b[39m(distances, key\u001b[38;5;241m=\u001b[39mdistances\u001b[38;5;241m.\u001b[39mget))\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(preds)\n",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m, in \u001b[0;36mLWP.<lambda>\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLWP\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Learning Vector Prototypes with configurable distance function\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     DISTANCE_FUNCTIONS \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x, y: np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(x \u001b[38;5;241m-\u001b[39m y),\n\u001b[1;32m----> 9\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x, y: \u001b[43mcosine_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanhattan\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x, y: manhattan_distances(x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), y\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x, y, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m: np\u001b[38;5;241m.\u001b[39mpower(np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mpower(np\u001b[38;5;241m.\u001b[39mabs(x \u001b[38;5;241m-\u001b[39m y), p)), \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mp)\n\u001b[0;32m     12\u001b[0m     }\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, distance_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdistance_params):\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m            distance_params (dict): Additional parameters for the distance function\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\pairwise.py:1108\u001b[0m, in \u001b[0;36mcosine_distances\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine distance between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1074\u001b[0m \n\u001b[0;32m   1075\u001b[0m \u001b[38;5;124;03mCosine distance is defined as 1.0 minus the cosine similarity.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;124;03m       [0.42..., 0.18...]])\u001b[39;00m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# 1.0 - cosine_similarity(X, Y) without copy\u001b[39;00m\n\u001b[1;32m-> 1108\u001b[0m S \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1109\u001b[0m S \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1110\u001b[0m S \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\pairwise.py:1657\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1614\u001b[0m \n\u001b[0;32m   1615\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1653\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1657\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1659\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\pairwise.py:164\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    155\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    156\u001b[0m         X,\n\u001b[0;32m    157\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 164\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    173\u001b[0m         Y,\n\u001b[0;32m    174\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    179\u001b[0m     )\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:1003\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    997\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1000\u001b[0m     )\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1003\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# error message.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 122\u001b[0m     first_pass_isfinite \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39misfinite(\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:2324\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2321\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   2322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m-> 2324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2325\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate on D2-D10\n",
    "for i in range(2, 11):\n",
    "    t = torch.load(os.path.join('dataset', 'part_one_dataset', 'eval_data', f'{i}_eval_data.tar.pth') ,weights_only=False)\n",
    "    evaluate_on_eval_embeddings(part_one_embed_dir, dataset_idx=i, model=kd_lwp_model, ground_truth = t['targets']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize a 10x10 matrix to store the accuracies\n",
    "results = []\n",
    "\n",
    "# Loop through datasets 1 to 10\n",
    "for i in range(2, 11):\n",
    "    row = []\n",
    "    # For each dataset, compute accuracy for D1 to Di\n",
    "    for j in range(2, i+1):\n",
    "        \n",
    "        # Evaluate the model on the current dataset\n",
    "        eval_results = evaluate_on_eval_embeddings(part_one_embed_dir, dataset_idx=j, model=lwp_model, ground_truth = t['targets'])\n",
    "        \n",
    "        # Extract the accuracy (if ground_truth is provided)\n",
    "        accuracy = eval_results[\"accuracy\"] if \"accuracy\" in eval_results else None\n",
    "        row.append(accuracy)\n",
    "    \n",
    "    # Add the row to the results list\n",
    "    results.append(row)\n",
    "\n",
    "# Create a 10x10 DataFrame with the results\n",
    "df = pd.DataFrame(results, columns=[f'Dataset {i}' for i in range(1, 11)], index=[f'Dataset {i}' for i in range(1, 11)])\n",
    "\n",
    "# Flip the rows and columns (transpose the DataFrame)\n",
    "df_transposed = df.transpose()\n",
    "\n",
    "# Print the resulting matrix (now flipped)\n",
    "print(df_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset D11 from part_2_vit_embeds\\train_embeds_1.pt...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0002\n",
      "Processing dataset D12 from part_2_vit_embeds\\train_embeds_2.pt...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0005\n",
      "Processing dataset D13 from part_2_vit_embeds\\train_embeds_3.pt...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0004\n",
      "Processing dataset D14 from part_2_vit_embeds\\train_embeds_4.pt...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0004\n",
      "Processing dataset D15 from part_2_vit_embeds\\train_embeds_5.pt...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0004\n",
      "Processing dataset D16 from part_2_vit_embeds\\train_embeds_6.pt...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0004\n",
      "Processing dataset D17 from part_2_vit_embeds\\train_embeds_7.pt...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0005\n",
      "Processing dataset D18 from part_2_vit_embeds\\train_embeds_8.pt...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0003\n",
      "Processing dataset D19 from part_2_vit_embeds\\train_embeds_9.pt...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0009\n",
      "Processing dataset D20 from part_2_vit_embeds\\train_embeds_10.pt...\n",
      "Selecting top 1250 samples out of 2500 (percentage: 50.0%)...\n",
      "Distillation Loss: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# Process D11-D20 (unlabeled datasets) with knowledge distillation\n",
    "for i in range(11, 21):\n",
    "    train_path = os.path.join(part_two_embed_dir, f'train_embeds_{i-10}.pt')\n",
    "    print(f\"Processing dataset D{i} from {train_path}...\")\n",
    "    \n",
    "    # Load train embeddings\n",
    "    train_embeddings = torch.load(train_path, weights_only=False)\n",
    "    \n",
    "    # Perform knowledge distillation-based learning\n",
    "    kd_lwp_model.update_model(train_embeddings)\n",
    "    pseudo_labels = kd_lwp_model.predict(train_embeddings)\n",
    "\n",
    "    #FIXME: Uncomment this line to update the model with the new data, where to get the pseudo labels from?\n",
    "    #kd_lwp_model.fit(train_embeddings, pseudo_labels)\n",
    "    \n",
    "    models.append(copy.deepcopy(kd_lwp_model))\n",
    "    \n",
    "    # Evaluate or predict on eval set if needed\n",
    "    eval_path = os.path.join(part_two_embed_dir, f'eval_embeds_{i-10}.pt')\n",
    "    eval_embeddings = torch.load(eval_path, weights_only=False)\n",
    "    predictions = kd_lwp_model.predict(eval_embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on dataset 1...\n",
      "Accuracy on eval set 1: 81.32%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       238\n",
      "           1       0.86      0.92      0.89       262\n",
      "           2       0.92      0.66      0.77       256\n",
      "           3       0.62      0.78      0.69       255\n",
      "           4       0.76      0.84      0.80       268\n",
      "           5       0.71      0.78      0.75       246\n",
      "           6       0.83      0.83      0.83       225\n",
      "           7       0.88      0.77      0.82       259\n",
      "           8       0.93      0.84      0.88       236\n",
      "           9       0.92      0.86      0.89       255\n",
      "\n",
      "    accuracy                           0.81      2500\n",
      "   macro avg       0.83      0.81      0.82      2500\n",
      "weighted avg       0.83      0.81      0.81      2500\n",
      "\n",
      "Evaluating on dataset 2...\n",
      "Accuracy on eval set 2: 67.44%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.87      0.62       238\n",
      "           1       0.95      0.39      0.56       262\n",
      "           2       0.95      0.30      0.46       256\n",
      "           3       0.62      0.51      0.56       255\n",
      "           4       0.71      0.75      0.73       268\n",
      "           5       0.64      0.82      0.72       246\n",
      "           6       0.63      0.89      0.74       225\n",
      "           7       0.81      0.74      0.78       259\n",
      "           8       0.76      0.84      0.80       236\n",
      "           9       0.67      0.68      0.68       255\n",
      "\n",
      "    accuracy                           0.67      2500\n",
      "   macro avg       0.72      0.68      0.66      2500\n",
      "weighted avg       0.73      0.67      0.66      2500\n",
      "\n",
      "Evaluating on dataset 3...\n",
      "Accuracy on eval set 3: 84.60%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       238\n",
      "           1       0.92      0.89      0.90       262\n",
      "           2       0.96      0.62      0.76       256\n",
      "           3       0.76      0.74      0.75       255\n",
      "           4       0.76      0.89      0.82       268\n",
      "           5       0.81      0.84      0.83       246\n",
      "           6       0.85      0.91      0.88       225\n",
      "           7       0.88      0.88      0.88       259\n",
      "           8       0.89      0.92      0.90       236\n",
      "           9       0.83      0.94      0.88       255\n",
      "\n",
      "    accuracy                           0.85      2500\n",
      "   macro avg       0.85      0.85      0.85      2500\n",
      "weighted avg       0.85      0.85      0.84      2500\n",
      "\n",
      "Evaluating on dataset 4...\n",
      "Accuracy on eval set 4: 88.12%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       238\n",
      "           1       0.95      0.95      0.95       262\n",
      "           2       0.96      0.73      0.83       256\n",
      "           3       0.81      0.83      0.82       255\n",
      "           4       0.78      0.90      0.83       268\n",
      "           5       0.82      0.84      0.83       246\n",
      "           6       0.91      0.93      0.92       225\n",
      "           7       0.89      0.86      0.87       259\n",
      "           8       0.95      0.95      0.95       236\n",
      "           9       0.92      0.95      0.93       255\n",
      "\n",
      "    accuracy                           0.88      2500\n",
      "   macro avg       0.89      0.88      0.88      2500\n",
      "weighted avg       0.89      0.88      0.88      2500\n",
      "\n",
      "Evaluating on dataset 5...\n",
      "Accuracy on eval set 5: 89.08%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       238\n",
      "           1       0.96      0.95      0.96       262\n",
      "           2       0.97      0.77      0.86       256\n",
      "           3       0.84      0.81      0.82       255\n",
      "           4       0.81      0.91      0.86       268\n",
      "           5       0.83      0.85      0.84       246\n",
      "           6       0.94      0.92      0.93       225\n",
      "           7       0.86      0.91      0.88       259\n",
      "           8       0.94      0.93      0.94       236\n",
      "           9       0.90      0.96      0.93       255\n",
      "\n",
      "    accuracy                           0.89      2500\n",
      "   macro avg       0.89      0.89      0.89      2500\n",
      "weighted avg       0.89      0.89      0.89      2500\n",
      "\n",
      "Evaluating on dataset 6...\n",
      "Accuracy on eval set 6: 82.12%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81       238\n",
      "           1       0.87      0.95      0.91       262\n",
      "           2       0.99      0.58      0.73       256\n",
      "           3       0.70      0.74      0.72       255\n",
      "           4       0.80      0.82      0.81       268\n",
      "           5       0.83      0.78      0.80       246\n",
      "           6       0.73      0.91      0.81       225\n",
      "           7       0.84      0.87      0.85       259\n",
      "           8       0.94      0.79      0.86       236\n",
      "           9       0.89      0.92      0.90       255\n",
      "\n",
      "    accuracy                           0.82      2500\n",
      "   macro avg       0.83      0.82      0.82      2500\n",
      "weighted avg       0.83      0.82      0.82      2500\n",
      "\n",
      "Evaluating on dataset 7...\n",
      "Accuracy on eval set 7: 83.40%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       238\n",
      "           1       0.88      0.94      0.91       262\n",
      "           2       0.92      0.72      0.81       256\n",
      "           3       0.62      0.82      0.71       255\n",
      "           4       0.75      0.88      0.81       268\n",
      "           5       0.82      0.76      0.79       246\n",
      "           6       0.87      0.88      0.87       225\n",
      "           7       0.92      0.77      0.84       259\n",
      "           8       0.95      0.85      0.90       236\n",
      "           9       0.92      0.88      0.90       255\n",
      "\n",
      "    accuracy                           0.83      2500\n",
      "   macro avg       0.85      0.83      0.84      2500\n",
      "weighted avg       0.85      0.83      0.84      2500\n",
      "\n",
      "Evaluating on dataset 8...\n",
      "Accuracy on eval set 8: 82.36%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82       238\n",
      "           1       0.95      0.87      0.91       262\n",
      "           2       0.97      0.59      0.73       256\n",
      "           3       0.75      0.71      0.73       255\n",
      "           4       0.70      0.90      0.79       268\n",
      "           5       0.79      0.79      0.79       246\n",
      "           6       0.74      0.93      0.82       225\n",
      "           7       0.87      0.83      0.85       259\n",
      "           8       0.88      0.89      0.89       236\n",
      "           9       0.86      0.93      0.89       255\n",
      "\n",
      "    accuracy                           0.82      2500\n",
      "   macro avg       0.84      0.82      0.82      2500\n",
      "weighted avg       0.84      0.82      0.82      2500\n",
      "\n",
      "Evaluating on dataset 9...\n",
      "Accuracy on eval set 9: 69.08%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71       238\n",
      "           1       0.80      0.68      0.74       262\n",
      "           2       0.98      0.36      0.52       256\n",
      "           3       0.58      0.58      0.58       255\n",
      "           4       0.82      0.62      0.71       268\n",
      "           5       0.73      0.69      0.71       246\n",
      "           6       0.86      0.56      0.68       225\n",
      "           7       0.69      0.80      0.74       259\n",
      "           8       0.65      0.92      0.76       236\n",
      "           9       0.55      0.96      0.70       255\n",
      "\n",
      "    accuracy                           0.69      2500\n",
      "   macro avg       0.73      0.69      0.68      2500\n",
      "weighted avg       0.73      0.69      0.68      2500\n",
      "\n",
      "Evaluating on dataset 10...\n",
      "Accuracy on eval set 10: 86.68%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       238\n",
      "           1       0.96      0.90      0.93       262\n",
      "           2       0.97      0.68      0.80       256\n",
      "           3       0.82      0.82      0.82       255\n",
      "           4       0.81      0.84      0.83       268\n",
      "           5       0.88      0.82      0.85       246\n",
      "           6       0.82      0.96      0.88       225\n",
      "           7       0.83      0.90      0.86       259\n",
      "           8       0.94      0.91      0.92       236\n",
      "           9       0.84      0.96      0.90       255\n",
      "\n",
      "    accuracy                           0.87      2500\n",
      "   macro avg       0.87      0.87      0.87      2500\n",
      "weighted avg       0.87      0.87      0.87      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on D11-D20 (unlabeled datasets)\n",
    "for i in range(11, 21):\n",
    "    t = torch.load(os.path.join('dataset', 'part_two_dataset', 'eval_data', f'{i-10}_eval_data.tar.pth') ,weights_only=False)\n",
    "    evaluate_on_eval_embeddings(part_two_embed_dir, dataset_idx=i-10, model=lwp_model, ground_truth=t['targets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sad life\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANUSHKA SINGH\\AppData\\Local\\Temp\\ipykernel_36588\\3426393762.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  domains[j]['features'] = torch.load(os.path.join(save_dir,f'train_embeds_{j+1}.pt'))\n",
      "C:\\Users\\ANUSHKA SINGH\\AppData\\Local\\Temp\\ipykernel_36588\\3426393762.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  eval_domains[j]['features'] = torch.load(os.path.join(save_dir,f'eval_embeds_{j+1}.pt'))\n",
      "C:\\Users\\ANUSHKA SINGH\\AppData\\Local\\Temp\\ipykernel_36588\\3426393762.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  domains[j+10]['features'] = torch.load(os.path.join(save_dir,f'train_embeds_{j+1}.pt'))\n",
      "C:\\Users\\ANUSHKA SINGH\\AppData\\Local\\Temp\\ipykernel_36588\\3426393762.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  eval_domains[j+10]['features'] = torch.load(os.path.join(save_dir,f'eval_embeds_{j+1}.pt'))\n"
     ]
    }
   ],
   "source": [
    "domains = [{} for _ in range(20)]\n",
    "\n",
    "train_dir = os.path.join('dataset', 'part_one_dataset', 'train_data')\n",
    "eval_dir = os.path.join('dataset', 'part_one_dataset', 'eval_data')\n",
    "save_dir = os.path.join('part_1_vit_embeds')\n",
    "\n",
    "for j in range(10):\n",
    "    \n",
    "    train_path = os.path.join(train_dir, f'{j+1}_train_data.tar.pth')\n",
    "    t = torch.load(train_path, weights_only = False)\n",
    "    \n",
    "    domains[j]['labels'] = t['targets'] if 'targets' in t else None\n",
    "    domains[j]['features'] = torch.load(os.path.join(save_dir,f'train_embeds_{j+1}.pt'))\n",
    "    \n",
    "    \n",
    "eval_domains = [{} for _ in range(20)]\n",
    "\n",
    "for j in range(10):\n",
    "    \n",
    "    eval_path = os.path.join(eval_dir, f'{j+1}_eval_data.tar.pth')\n",
    "    t = torch.load(eval_path, weights_only = False)\n",
    "\n",
    "    data = t['data'] # both numpy.ndarray\n",
    "    \n",
    "    eval_domains[j]['labels'] = t['targets'] if 'targets' in t else None\n",
    "    eval_domains[j]['features'] = torch.load(os.path.join(save_dir,f'eval_embeds_{j+1}.pt'))\n",
    "    \n",
    "    \n",
    "\n",
    "train_dir = os.path.join('dataset', 'part_two_dataset', 'train_data')\n",
    "eval_dir = os.path.join('dataset', 'part_two_dataset', 'eval_data')\n",
    "save_dir = os.path.join('part_2_vit_embeds')\n",
    "\n",
    "for j in range(10):\n",
    "    \n",
    "    train_path = os.path.join(train_dir, f'{j+1}_train_data.tar.pth')\n",
    "    t = torch.load(train_path, weights_only = False)\n",
    "    \n",
    "    domains[j+10]['labels'] = t['targets'] if 'targets' in t else None\n",
    "    domains[j+10]['features'] = torch.load(os.path.join(save_dir,f'train_embeds_{j+1}.pt'))\n",
    "    \n",
    "\n",
    "for j in range(10):\n",
    "    \n",
    "    train_path = os.path.join(eval_dir, f'{j+1}_eval_data.tar.pth')\n",
    "    t = torch.load(train_path, weights_only = False)\n",
    "    \n",
    "    eval_domains[j+10]['labels'] = t['targets'] if 'targets' in t else None\n",
    "    eval_domains[j+10]['features'] = torch.load(os.path.join(save_dir,f'eval_embeds_{j+1}.pt'))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "1 done\n",
      "2 done\n",
      "3 done\n",
      "4 done\n",
      "5 done\n",
      "6 done\n",
      "7 done\n",
      "8 done\n",
      "9 done\n",
      "10 done\n",
      "11 done\n",
      "12 done\n",
      "13 done\n",
      "14 done\n",
      "15 done\n",
      "16 done\n",
      "17 done\n",
      "18 done\n",
      "19 done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for idx,domain in enumerate(domains):\n",
    "    \n",
    "    model = models[idx]\n",
    "    # print(model.class_counts)\n",
    "    \n",
    "    scores = []\n",
    "    for eval_domain in eval_domains[:idx+1]:\n",
    "        \n",
    "        features = eval_domain[' features']\n",
    "        labels = eval_domain['labels']\n",
    "        \n",
    "        preds = model.predict(features)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        \n",
    "        scores.append(acc)\n",
    "    \n",
    "    df[f'Domain {idx+1}'] = scores + [np.nan] * (len(eval_domains) - len(scores))\n",
    "    print(f\"{idx} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Domain 1  Domain 2  Domain 3  Domain 4  Domain 5  Domain 6  Domain 7   \n",
      "0      0.902    0.8696    0.8656    0.8624    0.8652    0.8652    0.8656  \\\n",
      "1        NaN    0.8776    0.8688    0.8668    0.8692    0.8716    0.8708   \n",
      "2        NaN       NaN    0.8820    0.8804    0.8788    0.8784    0.8784   \n",
      "3        NaN       NaN       NaN    0.8944    0.8920    0.8932    0.8960   \n",
      "4        NaN       NaN       NaN       NaN    0.8828    0.8828    0.8824   \n",
      "5        NaN       NaN       NaN       NaN       NaN    0.8864    0.8888   \n",
      "6        NaN       NaN       NaN       NaN       NaN       NaN    0.8808   \n",
      "7        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "8        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "9        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "10       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "11       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "12       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "13       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "14       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "15       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "16       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "17       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "18       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "19       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "\n",
      "    Domain 8  Domain 9  Domain 10  Domain 11  Domain 12  Domain 13  Domain 14   \n",
      "0     0.8596    0.8612     0.8540     0.6236     0.6380     0.6292     0.6604  \\\n",
      "1     0.8652    0.8684     0.8660     0.6136     0.6376     0.6268     0.6576   \n",
      "2     0.8756    0.8756     0.8772     0.6284     0.6268     0.6224     0.6488   \n",
      "3     0.8920    0.8912     0.8932     0.6420     0.6728     0.6520     0.6816   \n",
      "4     0.8796    0.8792     0.8824     0.6472     0.6492     0.6320     0.6632   \n",
      "5     0.8884    0.8868     0.8860     0.6400     0.6580     0.6424     0.6744   \n",
      "6     0.8776    0.8736     0.8780     0.6264     0.6540     0.6436     0.6700   \n",
      "7     0.8756    0.8728     0.8800     0.6388     0.6460     0.6296     0.6576   \n",
      "8        NaN    0.8768     0.8776     0.6448     0.6548     0.6400     0.6688   \n",
      "9        NaN       NaN     0.8888     0.6508     0.6460     0.6364     0.6572   \n",
      "10       NaN       NaN        NaN     0.5832     0.5656     0.5564     0.5796   \n",
      "11       NaN       NaN        NaN        NaN     0.5588     0.5396     0.5604   \n",
      "12       NaN       NaN        NaN        NaN        NaN     0.5996     0.6316   \n",
      "13       NaN       NaN        NaN        NaN        NaN        NaN     0.6548   \n",
      "14       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "15       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "16       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "17       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "18       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "19       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "    Domain 15  Domain 16  Domain 17  Domain 18  Domain 19  Domain 20  \n",
      "0      0.6276     0.6592     0.6660     0.6588     0.6572     0.6628  \n",
      "1      0.6148     0.6588     0.6644     0.6596     0.6572     0.6640  \n",
      "2      0.6228     0.6508     0.6540     0.6492     0.6488     0.6492  \n",
      "3      0.6348     0.6808     0.6856     0.6808     0.6760     0.6816  \n",
      "4      0.6268     0.6648     0.6680     0.6664     0.6612     0.6640  \n",
      "5      0.6308     0.6740     0.6744     0.6700     0.6700     0.6728  \n",
      "6      0.6340     0.6688     0.6736     0.6684     0.6692     0.6736  \n",
      "7      0.6244     0.6616     0.6636     0.6604     0.6568     0.6616  \n",
      "8      0.6272     0.6712     0.6724     0.6680     0.6676     0.6716  \n",
      "9      0.6204     0.6576     0.6648     0.6612     0.6572     0.6620  \n",
      "10     0.5440     0.5768     0.5800     0.5732     0.5632     0.5756  \n",
      "11     0.5340     0.5548     0.5588     0.5552     0.5460     0.5508  \n",
      "12     0.5972     0.6324     0.6380     0.6312     0.6264     0.6288  \n",
      "13     0.6120     0.6504     0.6576     0.6536     0.6500     0.6540  \n",
      "14     0.6200     0.6548     0.6624     0.6536     0.6584     0.6576  \n",
      "15        NaN     0.5988     0.6096     0.5984     0.5976     0.5952  \n",
      "16        NaN        NaN     0.5980     0.5952     0.5820     0.5904  \n",
      "17        NaN        NaN        NaN     0.6168     0.6104     0.6180  \n",
      "18        NaN        NaN        NaN        NaN     0.5436     0.5328  \n",
      "19        NaN        NaN        NaN        NaN        NaN     0.6396  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
