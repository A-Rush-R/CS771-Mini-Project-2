{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_train_dir = os.path.join('dataset', 'part_one_dataset', 'train_data')\n",
    "one_eval_dir = os.path.join('dataset', 'part_one_dataset', 'eval_data')\n",
    "two_train_dir = os.path.join('dataset', 'part_two_dataset', 'train_data')\n",
    "two_eval_dir = os.path.join('dataset', 'part_two_dataset', 'eval_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = [{} for _ in range(20)]\n",
    "eval_domains = [{} for _ in range(20)]\n",
    "\n",
    "for i in range(10):\n",
    "    domains[i] = torch.load(os.path.join(one_train_dir, f'{i+1}_train_data.tar.pth'), weights_only=False)\n",
    "    domains[i+10] = torch.load(os.path.join(two_train_dir, f'{i+1}_train_data.tar.pth'), weights_only=False)\n",
    "    eval_domains[i] = torch.load(os.path.join(one_eval_dir, f'{i+1}_eval_data.tar.pth'), weights_only=False)\n",
    "    eval_domains[i+10] = torch.load(os.path.join(two_eval_dir, f'{i+1}_eval_data.tar.pth'), weights_only=False)\n",
    "    \n",
    "    domains[i]['data'] = domains[i]['data'].reshape(2500, -1)\n",
    "    domains[i+10]['data'] = domains[i+10]['data'].reshape(2500, -1)\n",
    "    eval_domains[i]['data'] = eval_domains[i]['data'].reshape(2500, -1)\n",
    "    eval_domains[i+10]['data'] = eval_domains[i+10]['data'].reshape(2500, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_paths = [os.path.join(one_train_dir, f'{i+1}_train_data.tar.pth') for i in range(10)] + [os.path.join(two_train_dir, f'{i+1}_train_data.tar.pth') for i in range(10)]\n",
    "# eval_paths = [os.path.join(one_eval_dir, f'{i+1}_eval_data.tar.pth') for i in range(10)] + [os.path.join(two_eval_dir, f'{i+1}_eval_data.tar.pth') for i in range(10)]\n",
    "\n",
    "# eval_domains = [torch.load(eval_paths[i], weights_only=False) for i in range(20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lwp import LWP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class GMMGenerativeClassifier:\n",
    "    def __init__(self, n_components=3, n_classes=10, covariance_type='full', random_state=42):\n",
    "        \"\"\"\n",
    "        Initialize GMM-based generative classifier\n",
    "        \n",
    "        Args:\n",
    "            n_components (int): Number of Gaussian components per class\n",
    "            n_classes (int): Number of classes\n",
    "            covariance_type (str): Type of covariance parameters ('full', 'tied', 'diag', 'spherical')\n",
    "            random_state (int): Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.n_classes = n_classes\n",
    "        self.covariance_type = covariance_type\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Initialize a GMM for each class\n",
    "        self.gmms = [\n",
    "            GaussianMixture(\n",
    "                n_components=n_components,\n",
    "                covariance_type=covariance_type,\n",
    "                random_state=random_state\n",
    "            ) for _ in range(n_classes)\n",
    "        ]\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        self.class_priors = None\n",
    "        \n",
    "    def fit(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Fit the GMM classifier\n",
    "        \n",
    "        Args:\n",
    "            embeddings: Array of shape (n_samples, n_features)\n",
    "            labels: Array of shape (n_samples,)\n",
    "        \"\"\"\n",
    "        # Scale the embeddings\n",
    "        scaled_embeddings = self.scaler.fit_transform(embeddings)\n",
    "        \n",
    "        # Calculate class priors\n",
    "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "        self.class_priors = counts / len(unique_labels)\n",
    "        \n",
    "        # Fit GMM for each class\n",
    "        for class_idx in range(self.n_classes):\n",
    "            class_mask = (labels == class_idx)\n",
    "            class_embeddings = scaled_embeddings[class_mask]\n",
    "            \n",
    "            if len(class_embeddings) > 0:\n",
    "                self.gmms[class_idx].fit(class_embeddings)\n",
    "                \n",
    "    def predict_proba(self, embeddings):\n",
    "        \"\"\"\n",
    "        Predict class probabilities for embeddings\n",
    "        \n",
    "        Args:\n",
    "            embeddings: Array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            Array of shape (n_samples, n_classes) containing class probabilities\n",
    "        \"\"\"\n",
    "        scaled_embeddings = self.scaler.transform(embeddings)\n",
    "        \n",
    "        # Calculate log likelihood for each class\n",
    "        log_probs = np.zeros((len(embeddings), self.n_classes))\n",
    "        \n",
    "        for class_idx in range(self.n_classes):\n",
    "            # Get log likelihood and add log prior\n",
    "            log_probs[:, class_idx] = (\n",
    "                self.gmms[class_idx].score_samples(scaled_embeddings) + \n",
    "                np.log(self.class_priors[class_idx])\n",
    "            )\n",
    "        \n",
    "        # Convert log probabilities to probabilities\n",
    "        log_prob_sum = logsumexp(log_probs, axis=1)\n",
    "        probs = np.exp(log_probs - log_prob_sum[:, np.newaxis])\n",
    "        \n",
    "        return probs\n",
    "    \n",
    "    def predict(self, embeddings):\n",
    "        \"\"\"\n",
    "        Predict classes for embeddings\n",
    "        \n",
    "        Args:\n",
    "            embeddings: Array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            Array of shape (n_samples,) containing predicted classes\n",
    "        \"\"\"\n",
    "        probs = self.predict_proba(embeddings)\n",
    "        return np.argmax(probs, axis=1)\n",
    "    \n",
    "    def generate_samples(self, n_samples_per_class):\n",
    "        \"\"\"\n",
    "        Generate samples for each class\n",
    "        \n",
    "        Args:\n",
    "            n_samples_per_class (int): Number of samples to generate per class\n",
    "        Returns:\n",
    "            tuple: (generated_samples, labels)\n",
    "        \"\"\"\n",
    "        generated_samples = []\n",
    "        labels = []\n",
    "        \n",
    "        for class_idx in range(self.n_classes):\n",
    "            # Generate samples from the GMM\n",
    "            samples, _ = self.gmms[class_idx].sample(n_samples_per_class)\n",
    "            \n",
    "            # Inverse transform to original space\n",
    "            samples = self.scaler.inverse_transform(samples)\n",
    "            \n",
    "            generated_samples.append(samples)\n",
    "            labels.extend([class_idx] * n_samples_per_class)\n",
    "            \n",
    "        return np.vstack(generated_samples), np.array(labels)\n",
    "\n",
    "def logsumexp(x, axis=None):\n",
    "    \"\"\"Compute log(sum(exp(x))) in a numerically stable way\"\"\"\n",
    "    x_max = np.max(x, axis=axis, keepdims=True)\n",
    "    return x_max + np.log(np.sum(np.exp(x - x_max), axis=axis, keepdims=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 253, 1: 243, 2: 255, 3: 244, 4: 262, 5: 236, 6: 250, 7: 253, 8: 254, 9: 250}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 710, 1: 370, 2: 373, 3: 287, 4: 412, 5: 496, 6: 928, 7: 360, 8: 447, 9: 617}\n",
      "{0: 1155, 1: 516, 2: 543, 3: 343, 4: 622, 5: 711, 6: 1576, 7: 483, 8: 657, 9: 894}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the classifier\n",
    "model = GMMGenerativeClassifier(n_components=3, n_classes=10)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "model = LWP(distance_metric='manhattan')\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for idx,domain in enumerate(domains):\n",
    "    \n",
    "    x_test = domain['data']\n",
    "    y_pred = model.predict(x_test) if 'targets' not in domain else domain['targets']\n",
    "    \n",
    "    model.fit(x_test, y_pred)\n",
    "    print(model.class_counts)\n",
    "    del domain\n",
    "    \n",
    "    scores = []\n",
    "    for eval_domain in eval_domains[:idx+1]:\n",
    "        \n",
    "        features = eval_domain['data']\n",
    "        labels = eval_domain['targets']\n",
    "        \n",
    "        preds = model.predict(features)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        \n",
    "        scores.append(acc)\n",
    "        \n",
    "    df[f'Domain {idx+1}'] = scores + [np.nan] * (20 - len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain 1</th>\n",
       "      <th>Domain 2</th>\n",
       "      <th>Domain 3</th>\n",
       "      <th>Domain 4</th>\n",
       "      <th>Domain 5</th>\n",
       "      <th>Domain 6</th>\n",
       "      <th>Domain 7</th>\n",
       "      <th>Domain 8</th>\n",
       "      <th>Domain 9</th>\n",
       "      <th>Domain 10</th>\n",
       "      <th>Domain 11</th>\n",
       "      <th>Domain 12</th>\n",
       "      <th>Domain 13</th>\n",
       "      <th>Domain 14</th>\n",
       "      <th>Domain 15</th>\n",
       "      <th>Domain 16</th>\n",
       "      <th>Domain 17</th>\n",
       "      <th>Domain 18</th>\n",
       "      <th>Domain 19</th>\n",
       "      <th>Domain 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.8908</td>\n",
       "      <td>0.8904</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.8884</td>\n",
       "      <td>0.8872</td>\n",
       "      <td>0.8868</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>0.8844</td>\n",
       "      <td>0.8832</td>\n",
       "      <td>0.8832</td>\n",
       "      <td>0.8844</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.8828</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.8820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.8996</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>0.8924</td>\n",
       "      <td>0.8912</td>\n",
       "      <td>0.8904</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.8884</td>\n",
       "      <td>0.8872</td>\n",
       "      <td>0.8876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.9076</td>\n",
       "      <td>0.9068</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.9064</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.9024</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.9004</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.8944</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>0.8916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9208</td>\n",
       "      <td>0.9204</td>\n",
       "      <td>0.9188</td>\n",
       "      <td>0.9180</td>\n",
       "      <td>0.9176</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.9168</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.9144</td>\n",
       "      <td>0.9148</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.9128</td>\n",
       "      <td>0.9128</td>\n",
       "      <td>0.9124</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.9088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9064</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.9008</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.8952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9128</td>\n",
       "      <td>0.9132</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>0.9148</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>0.9116</td>\n",
       "      <td>0.9124</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.9104</td>\n",
       "      <td>0.9104</td>\n",
       "      <td>0.9088</td>\n",
       "      <td>0.9068</td>\n",
       "      <td>0.9068</td>\n",
       "      <td>0.9044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9064</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.9024</td>\n",
       "      <td>0.9024</td>\n",
       "      <td>0.9016</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.9008</td>\n",
       "      <td>0.9008</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.8992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.8940</td>\n",
       "      <td>0.8944</td>\n",
       "      <td>0.8940</td>\n",
       "      <td>0.8932</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>0.8920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.9064</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.9024</td>\n",
       "      <td>0.9004</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.8972</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.8964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9088</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>0.9064</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.9016</td>\n",
       "      <td>0.9016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7908</td>\n",
       "      <td>0.7928</td>\n",
       "      <td>0.7916</td>\n",
       "      <td>0.7916</td>\n",
       "      <td>0.7904</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>0.7884</td>\n",
       "      <td>0.7876</td>\n",
       "      <td>0.7848</td>\n",
       "      <td>0.7844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6288</td>\n",
       "      <td>0.6304</td>\n",
       "      <td>0.6296</td>\n",
       "      <td>0.6308</td>\n",
       "      <td>0.6304</td>\n",
       "      <td>0.6304</td>\n",
       "      <td>0.6308</td>\n",
       "      <td>0.6324</td>\n",
       "      <td>0.6336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8460</td>\n",
       "      <td>0.8456</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.8436</td>\n",
       "      <td>0.8432</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>0.8772</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>0.8756</td>\n",
       "      <td>0.8756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8940</td>\n",
       "      <td>0.8940</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>0.8920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8128</td>\n",
       "      <td>0.8112</td>\n",
       "      <td>0.8112</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.8080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.8084</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>0.8060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8252</td>\n",
       "      <td>0.8248</td>\n",
       "      <td>0.8244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6964</td>\n",
       "      <td>0.6952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Domain 1  Domain 2  Domain 3  Domain 4  Domain 5  Domain 6  Domain 7  \\\n",
       "0      0.902    0.8936    0.8908    0.8904    0.8900    0.8900    0.8892   \n",
       "1        NaN    0.9040    0.8996    0.8988    0.8976    0.8968    0.8952   \n",
       "2        NaN       NaN    0.9096    0.9076    0.9068    0.9072    0.9064   \n",
       "3        NaN       NaN       NaN    0.9208    0.9204    0.9188    0.9180   \n",
       "4        NaN       NaN       NaN       NaN    0.9064    0.9056    0.9052   \n",
       "5        NaN       NaN       NaN       NaN       NaN    0.9128    0.9132   \n",
       "6        NaN       NaN       NaN       NaN       NaN       NaN    0.9064   \n",
       "7        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "8        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "9        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "10       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "11       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "12       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "13       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "14       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "15       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "16       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "17       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "18       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "19       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "    Domain 8  Domain 9  Domain 10  Domain 11  Domain 12  Domain 13  Domain 14  \\\n",
       "0     0.8884    0.8872     0.8868     0.8852     0.8844     0.8832     0.8832   \n",
       "1     0.8956    0.8956     0.8952     0.8948     0.8920     0.8924     0.8912   \n",
       "2     0.9056    0.9056     0.9048     0.9024     0.9012     0.9004     0.8992   \n",
       "3     0.9176    0.9172     0.9168     0.9160     0.9152     0.9144     0.9148   \n",
       "4     0.9044    0.9040     0.9036     0.9036     0.9008     0.8992     0.8992   \n",
       "5     0.9140    0.9148     0.9140     0.9116     0.9124     0.9096     0.9100   \n",
       "6     0.9052    0.9044     0.9048     0.9048     0.9036     0.9024     0.9024   \n",
       "7     0.8984    0.8988     0.8992     0.8976     0.8960     0.8948     0.8948   \n",
       "8        NaN    0.9072     0.9064     0.9040     0.9024     0.9004     0.9000   \n",
       "9        NaN       NaN     0.9088     0.9080     0.9064     0.9048     0.9056   \n",
       "10       NaN       NaN        NaN     0.7908     0.7928     0.7916     0.7916   \n",
       "11       NaN       NaN        NaN        NaN     0.6288     0.6304     0.6296   \n",
       "12       NaN       NaN        NaN        NaN        NaN     0.8460     0.8456   \n",
       "13       NaN       NaN        NaN        NaN        NaN        NaN     0.8796   \n",
       "14       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "15       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "16       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "17       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "18       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "19       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "    Domain 15  Domain 16  Domain 17  Domain 18  Domain 19  Domain 20  \n",
       "0      0.8844     0.8820     0.8824     0.8828     0.8816     0.8820  \n",
       "1      0.8904     0.8896     0.8900     0.8884     0.8872     0.8876  \n",
       "2      0.8988     0.8960     0.8944     0.8936     0.8920     0.8916  \n",
       "3      0.9152     0.9128     0.9128     0.9124     0.9096     0.9088  \n",
       "4      0.8988     0.8976     0.8968     0.8960     0.8948     0.8952  \n",
       "5      0.9104     0.9104     0.9088     0.9068     0.9068     0.9044  \n",
       "6      0.9016     0.9012     0.9008     0.9008     0.8992     0.8992  \n",
       "7      0.8940     0.8944     0.8940     0.8932     0.8928     0.8920  \n",
       "8      0.8992     0.8972     0.8968     0.8976     0.8956     0.8964  \n",
       "9      0.9052     0.9044     0.9036     0.9036     0.9016     0.9016  \n",
       "10     0.7904     0.7888     0.7884     0.7876     0.7848     0.7844  \n",
       "11     0.6308     0.6304     0.6304     0.6308     0.6324     0.6336  \n",
       "12     0.8464     0.8448     0.8436     0.8432     0.8440     0.8432  \n",
       "13     0.8788     0.8784     0.8772     0.8768     0.8756     0.8756  \n",
       "14     0.8940     0.8940     0.8936     0.8936     0.8928     0.8920  \n",
       "15        NaN     0.8128     0.8112     0.8112     0.8076     0.8080  \n",
       "16        NaN        NaN     0.8080     0.8084     0.8052     0.8060  \n",
       "17        NaN        NaN        NaN     0.8252     0.8248     0.8244  \n",
       "18        NaN        NaN        NaN        NaN     0.6964     0.6952  \n",
       "19        NaN        NaN        NaN        NaN        NaN     0.8652  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "771",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
