{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 2.8574328422546387\n",
      "Loss components: {'ce_loss': 2.358193874359131, 'contrastive_loss': 0.9984779357910156, 'distill_loss': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from randmix import RandMix, SimpleAutoencoder, AdaIN\n",
    "from top2 import Top2PseudoLabeling\n",
    "from pca import DomainAlignmentModel, FeatureExtractor, LinearLayerPrototypes\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('dataset', 'part_one_dataset', 'train_data')\n",
    "eval_dir = os.path.join('dataset', 'part_one_dataset', 'eval_data')\n",
    "train_path = os.path.join(train_dir, '1_train_data.tar.pth')\n",
    "eval_path = os.path.join(eval_dir, '1_eval_data.tar.pth')\n",
    "\n",
    "t = torch.load(train_path, weights_only = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'targets'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Top2PseudoLabeling.__init__() missing 1 required positional argument: 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m randmix \u001b[38;5;241m=\u001b[39m RandMix()\n\u001b[0;32m      2\u001b[0m pca \u001b[38;5;241m=\u001b[39m DomainAlignmentModel(feature_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m t2pl \u001b[38;5;241m=\u001b[39m \u001b[43mTop2PseudoLabeling\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Top2PseudoLabeling.__init__() missing 1 required positional argument: 'model'"
     ]
    }
   ],
   "source": [
    "randmix = RandMix()\n",
    "pca = DomainAlignmentModel(feature_dim=128, num_classes=20)\n",
    "t2pl = Top2PseudoLabeling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LWPModel(torch.nn.Module):\n",
    "    def __init__(self, feature_dim, num_classes):\n",
    "        super(LWPModel, self).__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.randmix = RandMix()\n",
    "        self.pca = PCA()\n",
    "        self.t2pl = Top2PseudoLabeling()\n",
    "        # Feature extractor and classifier\n",
    "        self.feature_extractor = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 64, 3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            torch.nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(128 * 8 * 8, feature_dim)\n",
    "        )\n",
    "        self.classifier = torch.nn.Linear(feature_dim, num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "# Function to load datasets\n",
    "def load_data(path):\n",
    "    data_dict = torch.load(path)\n",
    "    images = torch.tensor(data_dict['data']).float()\n",
    "    targets = torch.tensor(data_dict.get('targets', torch.zeros(images.size(0)).long()))  # Zero labels if no targets\n",
    "    return TensorDataset(images, targets)\n",
    "\n",
    "# Training, pseudo-labeling, and evaluation setup\n",
    "feature_dim = 256\n",
    "num_classes = 10  # Adjust as needed\n",
    "num_models = 20\n",
    "\n",
    "models = []\n",
    "for i in range(num_models):\n",
    "    print(f\"Training model {i+1}/{num_models}\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = LWPModel(feature_dim, num_classes).cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    train_path = f\"{train_dir}/{i+1}_train_data.tar.pth\"\n",
    "    eval_path = f\"{eval_dir}/{i+1}_eval_data.tar.pth\"\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset = load_data(train_path)\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    # Supervised training for the first dataset with true labels\n",
    "    if i == 0:\n",
    "        for epoch in range(10):\n",
    "            model.train()\n",
    "            for images, labels in dataloader:\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "                # RandMix augmentation\n",
    "                augmented_images = randmix(images)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(augmented_images)\n",
    "                loss = torch.nn.CrossEntropyLoss()(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        print(\"Initial supervised model trained.\")\n",
    "\n",
    "    # Generate pseudo labels for unlabeled datasets\n",
    "    else:\n",
    "        model.eval()\n",
    "        pseudo_labels = t2pl.generate_pseudo_labels(model, dataloader, num_classes)\n",
    "        pseudo_dataset = TensorDataset(dataset[:][0], pseudo_labels)  # Replace targets with pseudo labels\n",
    "        pseudo_dataloader = DataLoader(pseudo_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "        # Train with pseudo labels using PCA for alignment\n",
    "        for epoch in range(10):\n",
    "            model.train()\n",
    "            for images, pseudo_labels in pseudo_dataloader:\n",
    "                images, pseudo_labels = images.cuda(), pseudo_labels.cuda()\n",
    "                # RandMix augmentation\n",
    "                augmented_images = randmix(images)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(augmented_images)\n",
    "                \n",
    "                # Compute losses\n",
    "                ce_loss = torch.nn.CrossEntropyLoss()(logits, pseudo_labels)\n",
    "                features = model.feature_extractor(images)\n",
    "                pca_loss = pca(features, pseudo_labels, model.classifier.weight)\n",
    "                total_loss = ce_loss + 0.5 * pca_loss  # Weighted loss\n",
    "                total_loss.backward()\n",
    "                optimizer.step()\n",
    "        print(f\"Model {i+1} trained with pseudo labels.\")\n",
    "\n",
    "    # Save trained model for later analysis or reuse\n",
    "    models.append(model)\n",
    "\n",
    "    # Evaluation\n",
    "    eval_dataset = load_data(eval_path)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=64, shuffle=False)\n",
    "    correct, total = 0, 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in eval_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            logits = model(images)\n",
    "            _, predicted = logits.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Evaluation Accuracy for model {i+1}: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = t['data'].reshape(-1, 3, 32, 32)\n",
    "labels = t['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = torch.nn.Identity()  # Remove the final layer to get feature vectors\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 3, 32, 32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 9 9 ... 9 9 7]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
