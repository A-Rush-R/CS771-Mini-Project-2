{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('dataset', 'part_one_dataset', 'train_data')\n",
    "eval_dir = os.path.join('dataset', 'part_one_dataset', 'eval_data')\n",
    "\n",
    "train_path = os.path.join(train_dir, '1_train_data.tar.pth')\n",
    "eval_path = os.path.join(eval_dir, '1_eval_data.tar.pth')\n",
    "\n",
    "t = torch.load(train_path, weights_only = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "\n",
    "# Load a pre-trained ResNet model\n",
    "resnet =  models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # Remove the last layer\n",
    "resnet.eval()  # Set to evaluation mode\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = resnet.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Example ndarray of shape (2500, 32, 32, 3)\n",
    "data, targets = t['data'], t['targets'] # both numpy.ndarray\n",
    "# Convert to PyTorch tensor\n",
    "X_tensor = torch.tensor(data, dtype=torch.float32)  # Convert to tensor\n",
    "X_tensor = X_tensor.permute(0, 3, 1, 2)  # Change shape to (2500, 3, 32, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2500, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 (ResNet input size)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "])\n",
    "\n",
    "tensor = X_tensor.float()\n",
    "\n",
    "transformed_images = []\n",
    "for image in tensor:\n",
    "    # Convert each image tensor (C, H, W) to PIL Image for transformation\n",
    "    transformed_image = transform(image)  # Apply the transformations\n",
    "    transformed_images.append(transformed_image)\n",
    "\n",
    "# 4. Stack the transformed images back into a batch\n",
    "preprocessed_tensor = torch.stack(transformed_images)  # Shape: (2500, 3, 224, 224)\n",
    "\n",
    "# 5. Check the shape of the preprocessed tensor\n",
    "print(preprocessed_tensor.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 255.5240,  255.5240,  255.5240,  ...,  644.1703,  644.1703,\n",
       "            644.1703],\n",
       "          [ 255.5240,  255.5240,  255.5240,  ...,  644.1703,  644.1703,\n",
       "            644.1703],\n",
       "          [ 255.5240,  255.5240,  255.5240,  ...,  644.1703,  644.1703,\n",
       "            644.1703],\n",
       "          ...,\n",
       "          [ 770.8079,  770.8079,  770.8079,  ...,  535.0000,  535.0000,\n",
       "            535.0000],\n",
       "          [ 770.8079,  770.8079,  770.8079,  ...,  535.0000,  535.0000,\n",
       "            535.0000],\n",
       "          [ 770.8079,  770.8079,  770.8079,  ...,  535.0000,  535.0000,\n",
       "            535.0000]],\n",
       "\n",
       "         [[ 274.7500,  274.7500,  274.7500,  ...,  551.5357,  551.5357,\n",
       "            551.5357],\n",
       "          [ 274.7500,  274.7500,  274.7500,  ...,  551.5357,  551.5357,\n",
       "            551.5357],\n",
       "          [ 274.7500,  274.7500,  274.7500,  ...,  551.5357,  551.5357,\n",
       "            551.5357],\n",
       "          ...,\n",
       "          [ 640.8214,  640.8214,  640.8214,  ...,  408.6786,  408.6786,\n",
       "            408.6786],\n",
       "          [ 640.8214,  640.8214,  640.8214,  ...,  408.6786,  408.6786,\n",
       "            408.6786],\n",
       "          [ 640.8214,  640.8214,  640.8214,  ...,  408.6786,  408.6786,\n",
       "            408.6786]],\n",
       "\n",
       "         [[ 278.1956,  278.1956,  278.1956,  ...,  455.9734,  455.9734,\n",
       "            455.9734],\n",
       "          [ 278.1956,  278.1956,  278.1956,  ...,  455.9734,  455.9734,\n",
       "            455.9734],\n",
       "          [ 278.1956,  278.1956,  278.1956,  ...,  455.9734,  455.9734,\n",
       "            455.9734],\n",
       "          ...,\n",
       "          [ 513.7512,  513.7512,  513.7512,  ...,  318.1956,  318.1956,\n",
       "            318.1956],\n",
       "          [ 513.7512,  513.7512,  513.7512,  ...,  318.1956,  318.1956,\n",
       "            318.1956],\n",
       "          [ 513.7512,  513.7512,  513.7512,  ...,  318.1956,  318.1956,\n",
       "            318.1956]]],\n",
       "\n",
       "\n",
       "        [[[ 670.3712,  670.3712,  670.3712,  ...,  342.8603,  342.8603,\n",
       "            342.8603],\n",
       "          [ 670.3712,  670.3712,  670.3712,  ...,  342.8603,  342.8603,\n",
       "            342.8603],\n",
       "          [ 670.3712,  670.3712,  670.3712,  ...,  342.8603,  342.8603,\n",
       "            342.8603],\n",
       "          ...,\n",
       "          [ 709.6725,  709.6725,  709.6725,  ...,  622.3362,  622.3362,\n",
       "            622.3362],\n",
       "          [ 709.6725,  709.6725,  709.6725,  ...,  622.3362,  622.3362,\n",
       "            622.3362],\n",
       "          [ 709.6725,  709.6725,  709.6725,  ...,  622.3362,  622.3362,\n",
       "            622.3362]],\n",
       "\n",
       "         [[ 788.1429,  788.1429,  788.1429,  ...,  359.5714,  359.5714,\n",
       "            359.5714],\n",
       "          [ 788.1429,  788.1429,  788.1429,  ...,  359.5714,  359.5714,\n",
       "            359.5714],\n",
       "          [ 788.1429,  788.1429,  788.1429,  ...,  359.5714,  359.5714,\n",
       "            359.5714],\n",
       "          ...,\n",
       "          [ 658.6786,  658.6786,  658.6786,  ...,  591.7143,  591.7143,\n",
       "            591.7143],\n",
       "          [ 658.6786,  658.6786,  658.6786,  ...,  591.7143,  591.7143,\n",
       "            591.7143],\n",
       "          [ 658.6786,  658.6786,  658.6786,  ...,  591.7143,  591.7143,\n",
       "            591.7143]],\n",
       "\n",
       "         [[ 829.3066,  829.3066,  829.3066,  ...,  309.3067,  309.3067,\n",
       "            309.3067],\n",
       "          [ 829.3066,  829.3066,  829.3066,  ...,  309.3067,  309.3067,\n",
       "            309.3067],\n",
       "          [ 829.3066,  829.3066,  829.3066,  ...,  309.3067,  309.3067,\n",
       "            309.3067],\n",
       "          ...,\n",
       "          [ 531.5289,  531.5289,  531.5289,  ...,  638.1956,  638.1956,\n",
       "            638.1956],\n",
       "          [ 531.5289,  531.5289,  531.5289,  ...,  638.1956,  638.1956,\n",
       "            638.1956],\n",
       "          [ 531.5289,  531.5289,  531.5289,  ...,  638.1956,  638.1956,\n",
       "            638.1956]]],\n",
       "\n",
       "\n",
       "        [[[1111.4192, 1111.4192, 1111.4192,  ..., 1102.6855, 1102.6855,\n",
       "           1102.6855],\n",
       "          [1111.4192, 1111.4192, 1111.4192,  ..., 1102.6855, 1102.6855,\n",
       "           1102.6855],\n",
       "          [1111.4192, 1111.4192, 1111.4192,  ..., 1102.6855, 1102.6855,\n",
       "           1102.6855],\n",
       "          ...,\n",
       "          [ 460.7642,  460.7642,  460.7642,  ...,  347.2271,  347.2271,\n",
       "            347.2271],\n",
       "          [ 460.7642,  460.7642,  460.7642,  ...,  347.2271,  347.2271,\n",
       "            347.2271],\n",
       "          [ 460.7642,  460.7642,  460.7642,  ...,  347.2271,  347.2271,\n",
       "            347.2271]],\n",
       "\n",
       "         [[1136.3572, 1136.3572, 1136.3572,  ..., 1127.4286, 1127.4286,\n",
       "           1127.4286],\n",
       "          [1136.3572, 1136.3572, 1136.3572,  ..., 1127.4286, 1127.4286,\n",
       "           1127.4286],\n",
       "          [1136.3572, 1136.3572, 1136.3572,  ..., 1127.4286, 1127.4286,\n",
       "           1127.4286],\n",
       "          ...,\n",
       "          [ 502.4286,  502.4286,  502.4286,  ...,  381.8929,  381.8929,\n",
       "            381.8929],\n",
       "          [ 502.4286,  502.4286,  502.4286,  ...,  381.8929,  381.8929,\n",
       "            381.8929],\n",
       "          [ 502.4286,  502.4286,  502.4286,  ...,  381.8929,  381.8929,\n",
       "            381.8929]],\n",
       "\n",
       "         [[1131.5289, 1131.5289, 1131.5289,  ..., 1122.6400, 1122.6400,\n",
       "           1122.6400],\n",
       "          [1131.5289, 1131.5289, 1131.5289,  ..., 1122.6400, 1122.6400,\n",
       "           1122.6400],\n",
       "          [1131.5289, 1131.5289, 1131.5289,  ..., 1122.6400, 1122.6400,\n",
       "           1122.6400],\n",
       "          ...,\n",
       "          [ 464.8622,  464.8622,  464.8622,  ...,  371.5289,  371.5289,\n",
       "            371.5289],\n",
       "          [ 464.8622,  464.8622,  464.8622,  ...,  371.5289,  371.5289,\n",
       "            371.5289],\n",
       "          [ 464.8622,  464.8622,  464.8622,  ...,  371.5289,  371.5289,\n",
       "            371.5289]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[1098.3187, 1098.3187, 1098.3187,  ..., 1067.7511, 1067.7511,\n",
       "           1067.7511],\n",
       "          [1098.3187, 1098.3187, 1098.3187,  ..., 1067.7511, 1067.7511,\n",
       "           1067.7511],\n",
       "          [1098.3187, 1098.3187, 1098.3187,  ..., 1067.7511, 1067.7511,\n",
       "           1067.7511],\n",
       "          ...,\n",
       "          [1080.8516, 1080.8516, 1080.8516,  ...,  443.2969,  443.2969,\n",
       "            443.2969],\n",
       "          [1080.8516, 1080.8516, 1080.8516,  ...,  443.2969,  443.2969,\n",
       "            443.2969],\n",
       "          [1080.8516, 1080.8516, 1080.8516,  ...,  443.2969,  443.2969,\n",
       "            443.2969]],\n",
       "\n",
       "         [[1114.0358, 1114.0358, 1114.0358,  ..., 1114.0358, 1114.0358,\n",
       "           1114.0358],\n",
       "          [1114.0358, 1114.0358, 1114.0358,  ..., 1114.0358, 1114.0358,\n",
       "           1114.0358],\n",
       "          [1114.0358, 1114.0358, 1114.0358,  ..., 1114.0358, 1114.0358,\n",
       "           1114.0358],\n",
       "          ...,\n",
       "          [1105.1072, 1105.1072, 1105.1072,  ...,  511.3571,  511.3571,\n",
       "            511.3571],\n",
       "          [1105.1072, 1105.1072, 1105.1072,  ...,  511.3571,  511.3571,\n",
       "            511.3571],\n",
       "          [1105.1072, 1105.1072, 1105.1072,  ...,  511.3571,  511.3571,\n",
       "            511.3571]],\n",
       "\n",
       "         [[1118.1956, 1118.1956, 1118.1956,  ..., 1095.9734, 1095.9734,\n",
       "           1095.9734],\n",
       "          [1118.1956, 1118.1956, 1118.1956,  ..., 1095.9734, 1095.9734,\n",
       "           1095.9734],\n",
       "          [1118.1956, 1118.1956, 1118.1956,  ..., 1095.9734, 1095.9734,\n",
       "           1095.9734],\n",
       "          ...,\n",
       "          [1104.8622, 1104.8622, 1104.8622,  ...,  513.7512,  513.7512,\n",
       "            513.7512],\n",
       "          [1104.8622, 1104.8622, 1104.8622,  ...,  513.7512,  513.7512,\n",
       "            513.7512],\n",
       "          [1104.8622, 1104.8622, 1104.8622,  ...,  513.7512,  513.7512,\n",
       "            513.7512]]],\n",
       "\n",
       "\n",
       "        [[[ 949.8472,  949.8472,  949.8472,  ...,  997.8821,  997.8821,\n",
       "            997.8821],\n",
       "          [ 949.8472,  949.8472,  949.8472,  ...,  997.8821,  997.8821,\n",
       "            997.8821],\n",
       "          [ 949.8472,  949.8472,  949.8472,  ...,  997.8821,  997.8821,\n",
       "            997.8821],\n",
       "          ...,\n",
       "          [ 853.7773,  853.7773,  853.7773,  ...,  535.0000,  535.0000,\n",
       "            535.0000],\n",
       "          [ 853.7773,  853.7773,  853.7773,  ...,  535.0000,  535.0000,\n",
       "            535.0000],\n",
       "          [ 853.7773,  853.7773,  853.7773,  ...,  535.0000,  535.0000,\n",
       "            535.0000]],\n",
       "\n",
       "         [[ 939.9286,  939.9286,  939.9286,  ..., 1020.2857, 1020.2857,\n",
       "           1020.2857],\n",
       "          [ 939.9286,  939.9286,  939.9286,  ..., 1020.2857, 1020.2857,\n",
       "           1020.2857],\n",
       "          [ 939.9286,  939.9286,  939.9286,  ..., 1020.2857, 1020.2857,\n",
       "           1020.2857],\n",
       "          ...,\n",
       "          [ 819.3929,  819.3929,  819.3929,  ...,  515.8214,  515.8214,\n",
       "            515.8214],\n",
       "          [ 819.3929,  819.3929,  819.3929,  ...,  515.8214,  515.8214,\n",
       "            515.8214],\n",
       "          [ 819.3929,  819.3929,  819.3929,  ...,  515.8214,  515.8214,\n",
       "            515.8214]],\n",
       "\n",
       "         [[ 967.0845,  967.0845,  967.0845,  ..., 1007.0845, 1007.0845,\n",
       "           1007.0845],\n",
       "          [ 967.0845,  967.0845,  967.0845,  ..., 1007.0845, 1007.0845,\n",
       "           1007.0845],\n",
       "          [ 967.0845,  967.0845,  967.0845,  ..., 1007.0845, 1007.0845,\n",
       "           1007.0845],\n",
       "          ...,\n",
       "          [ 824.8622,  824.8622,  824.8622,  ...,  447.0845,  447.0845,\n",
       "            447.0845],\n",
       "          [ 824.8622,  824.8622,  824.8622,  ...,  447.0845,  447.0845,\n",
       "            447.0845],\n",
       "          [ 824.8622,  824.8622,  824.8622,  ...,  447.0845,  447.0845,\n",
       "            447.0845]]],\n",
       "\n",
       "\n",
       "        [[[ 390.8952,  390.8952,  390.8952,  ...,  508.7991,  508.7991,\n",
       "            508.7991],\n",
       "          [ 390.8952,  390.8952,  390.8952,  ...,  508.7991,  508.7991,\n",
       "            508.7991],\n",
       "          [ 390.8952,  390.8952,  390.8952,  ...,  508.7991,  508.7991,\n",
       "            508.7991],\n",
       "          ...,\n",
       "          [ 596.1354,  596.1354,  596.1354,  ...,  465.1310,  465.1310,\n",
       "            465.1310],\n",
       "          [ 596.1354,  596.1354,  596.1354,  ...,  465.1310,  465.1310,\n",
       "            465.1310],\n",
       "          [ 596.1354,  596.1354,  596.1354,  ...,  465.1310,  465.1310,\n",
       "            465.1310]],\n",
       "\n",
       "         [[ 542.6071,  542.6071,  542.6071,  ...,  622.9643,  622.9643,\n",
       "            622.9643],\n",
       "          [ 542.6071,  542.6071,  542.6071,  ...,  622.9643,  622.9643,\n",
       "            622.9643],\n",
       "          [ 542.6071,  542.6071,  542.6071,  ...,  622.9643,  622.9643,\n",
       "            622.9643],\n",
       "          ...,\n",
       "          [ 712.2500,  712.2500,  712.2500,  ...,  645.2857,  645.2857,\n",
       "            645.2857],\n",
       "          [ 712.2500,  712.2500,  712.2500,  ...,  645.2857,  645.2857,\n",
       "            645.2857],\n",
       "          [ 712.2500,  712.2500,  712.2500,  ...,  645.2857,  645.2857,\n",
       "            645.2857]],\n",
       "\n",
       "         [[ 433.7511,  433.7511,  433.7511,  ...,  704.8622,  704.8622,\n",
       "            704.8622],\n",
       "          [ 433.7511,  433.7511,  433.7511,  ...,  704.8622,  704.8622,\n",
       "            704.8622],\n",
       "          [ 433.7511,  433.7511,  433.7511,  ...,  704.8622,  704.8622,\n",
       "            704.8622],\n",
       "          ...,\n",
       "          [ 518.1956,  518.1956,  518.1956,  ...,  420.4178,  420.4178,\n",
       "            420.4178],\n",
       "          [ 518.1956,  518.1956,  518.1956,  ...,  420.4178,  420.4178,\n",
       "            420.4178],\n",
       "          [ 518.1956,  518.1956,  518.1956,  ...,  420.4178,  420.4178,\n",
       "            420.4178]]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([250, 512])\n",
      "Embeddings shape: torch.Size([250, 512])\n",
      "Embeddings shape: torch.Size([250, 512])\n",
      "Embeddings shape: torch.Size([250, 512])\n",
      "Embeddings shape: torch.Size([250, 512])\n",
      "Embeddings shape: torch.Size([250, 512])\n",
      "Embeddings shape: torch.Size([250, 512])\n",
      "Embeddings shape: torch.Size([250, 512])\n",
      "Embeddings shape: torch.Size([250, 512])\n",
      "Embeddings shape: torch.Size([250, 512])\n"
     ]
    }
   ],
   "source": [
    "embeds = []\n",
    "\n",
    "for i in range(10) : \n",
    "    \n",
    "    preprocessed_batch = preprocessed_tensor[i*250:(i+1)*250]\n",
    "    preprocessed_batch = preprocessed_batch.to(device)\n",
    "\n",
    "    # 4. Get the embeddings (feature maps)\n",
    "    with torch.no_grad():  # Disable gradients for inference\n",
    "        feature_maps = resnet(preprocessed_batch)  # Shape will be (batch_size, 512, 1, 1)\n",
    "\n",
    "    # 5. Flatten the feature maps (optional)\n",
    "    embeddings = feature_maps.view(feature_maps.size(0), -1)  # Flatten to shape (batch_size, embedding_size)\n",
    "\n",
    "    # Print the embeddings shape (should be 2500 x 512)\n",
    "    print(\"Embeddings shape:\", embeddings.shape)\n",
    "    \n",
    "    embeds.append(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "class LearningWithPrototype:\n",
    "    def __init__(self, n_classes, feature_dim=512, learning_rate=0.001, model_name='resnet18', batch_size=32):\n",
    "        self.n_classes = n_classes\n",
    "        self.feature_dim = feature_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model_name = model_name\n",
    "        self.batch_size = batch_size\n",
    "        self.prototypes = None\n",
    "        self.feature_extractor = None\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def initialize_model(self):\n",
    "        \"\"\"Initialize the pre-trained feature extractor\"\"\"\n",
    "        resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # Remove the last layer\n",
    "        self.feature_extractor = resnet.to(self.device)  # Move model to GPU if available\n",
    "\n",
    "    def extract_features(self, images):\n",
    "        \"\"\"Convert images to features using the feature extractor\"\"\"\n",
    "        self.feature_extractor.eval()\n",
    "        features_list = []\n",
    "        \n",
    "        X_tensor = torch.tensor(images, dtype=torch.float32).to(self.device)  # Move images to device\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),  # Resize images to 224x224 (ResNet input size)\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "        ])\n",
    "\n",
    "        tensor = X_tensor.float()\n",
    "        processed_images = transform(tensor)\n",
    "        \n",
    "        # Create DataLoader for batch processing\n",
    "        dataset = TensorDataset(processed_images)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                batch = batch[0].to(self.device)  # Move batch to device\n",
    "                batch_features = self.feature_extractor(batch)\n",
    "                features_list.append(batch_features)\n",
    "        \n",
    "        return torch.cat(features_list, dim=0).cpu().numpy().reshape(-1, self.feature_dim)  # Move final output to CPU for numpy compatibility\n",
    "\n",
    "    def compute_prototypes(self, features, labels):\n",
    "        \"\"\"Compute class prototypes from features\"\"\"\n",
    "        prototypes = np.zeros((self.n_classes, self.feature_dim))\n",
    "        \n",
    "        features = features.reshape(features.shape[0], self.feature_dim)\n",
    "        \n",
    "        for i in range(self.n_classes):\n",
    "            if np.sum(labels == i) > 0:\n",
    "                prototypes[i] = np.mean(features[labels == i], axis=0)\n",
    "        return prototypes\n",
    "\n",
    "    def predict(self, features):\n",
    "        \"\"\"Predict labels based on distance to prototypes\"\"\"\n",
    "        distances = euclidean_distances(features, self.prototypes)\n",
    "        return np.argmin(distances, axis=1)\n",
    "\n",
    "    def fit_predict_iterate(self, datasets):\n",
    "        \"\"\"Iterative training and prediction on multiple datasets\"\"\"\n",
    "        all_predictions = []\n",
    "        \n",
    "        # Initialize model\n",
    "        self.initialize_model()\n",
    "        \n",
    "        # Initial feature extraction and prototype computation\n",
    "        X_init, y_init = datasets[0]\n",
    "        features_init = self.extract_features(X_init)\n",
    "        self.prototypes = self.compute_prototypes(features_init, y_init)\n",
    "        \n",
    "        # Store predictions for first dataset\n",
    "        all_predictions.append(y_init)\n",
    "        \n",
    "        # Iterate through remaining datasets\n",
    "        for i, (X_next, _) in enumerate(datasets[1:], 1):\n",
    "            print(f\"\\nProcessing dataset {i+1}\")\n",
    "            \n",
    "            # Extract features for current dataset\n",
    "            features_next = self.extract_features(X_next)\n",
    "            \n",
    "            # Predict labels using current prototypes\n",
    "            predicted_labels = self.predict(features_next)\n",
    "            all_predictions.append(predicted_labels)\n",
    "            \n",
    "            # Update prototypes with new features\n",
    "            features_next = self.extract_features(X_next)\n",
    "            self.prototypes = self.compute_prototypes(features_next, predicted_labels)\n",
    "        \n",
    "        return all_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for i in range (1, 11) :\n",
    "    train_path = os.path.join(train_dir, f'{i}_train_data.tar.pth')\n",
    "    data = torch.load(train_path, weights_only = False)\n",
    "    datasets.append((data['data'].reshape(-1,3,32,32), data['targets'] if 'targets' in data else np.zeros(data['data'].shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing dataset 2\n",
      "\n",
      "Processing dataset 3\n",
      "\n",
      "Processing dataset 4\n",
      "\n",
      "Processing dataset 5\n",
      "\n",
      "Processing dataset 6\n",
      "\n",
      "Processing dataset 7\n",
      "\n",
      "Processing dataset 8\n",
      "\n",
      "Processing dataset 9\n",
      "\n",
      "Processing dataset 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Process multiple datasets using Learning with Prototype with pre-trained feature extractor\n",
    "\n",
    "Parameters:\n",
    "datasets: List of tuples (X, y) where X is the image data and y is labels\n",
    "            First dataset should have labels, others can have dummy labels\n",
    "model_name: Name of the pre-trained model to use ('resnet18', 'resnet50', \n",
    "            'efficientnet_b0', or 'vit_b_16')\n",
    "\"\"\"\n",
    "# Initialize LwP model\n",
    "n_classes = 10\n",
    "lwp = LearningWithPrototype(\n",
    "    n_classes=n_classes,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "predictions = lwp.fit_predict_iterate(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 9 9 ... 9 9 7]\n",
      "[6 9 9 ... 8 6 5]\n",
      "[4 6 7 ... 0 8 3]\n",
      "[0 1 6 ... 1 2 5]\n",
      "[6 2 5 ... 9 9 6]\n",
      "[6 1 2 ... 3 6 7]\n",
      "[2 5 3 ... 5 4 5]\n",
      "[5 3 9 ... 7 0 8]\n",
      "[8 1 5 ... 6 1 6]\n",
      "[3 7 4 ... 2 9 5]\n"
     ]
    }
   ],
   "source": [
    "for pred in predictions : \n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "771",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
